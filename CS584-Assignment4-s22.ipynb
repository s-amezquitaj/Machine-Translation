{"cells":[{"cell_type":"markdown","metadata":{"id":"mOgaNXMLiD1b"},"source":["# CS 584 Assignment 4 -- Sequence to Sequence Models\n","\n","#### Name: Jose Amezquita"]},{"cell_type":"markdown","metadata":{"id":"sAveCNCtiD1f"},"source":["## In this assignment, you are required to follow the steps below:\n","1. Review the lecture slides.\n","2. Implement a Seq2Seq model.\n","\n","*** Please note that there are many online resources for Seq2Seq models, you are allowed to check them, but DO NOT DIRECTLY COPY from them. Otherwise, you will get ZERO for this assignment. ***"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive') #mounts google colab to my drive. Can be commented out when running locally"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J8cTgjwjPcka","executionInfo":{"status":"ok","timestamp":1651446624903,"user_tz":240,"elapsed":739,"user":{"displayName":"Pablo Amezquita","userId":"04689184241608460117"}},"outputId":"c7159ec0-3f4b-4fba-ce62-759d1d50f433"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/\"Colab Notebooks\"/\"CS584 HW4\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tAjqdsapRPj3","executionInfo":{"status":"ok","timestamp":1651446626750,"user_tz":240,"elapsed":130,"user":{"displayName":"Pablo Amezquita","userId":"04689184241608460117"}},"outputId":"abf9c2cc-188f-4206-e243-c8463e84defa"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/CS584 HW4\n"]}]},{"cell_type":"code","source":["%pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"Wyd2erYXRrsB","executionInfo":{"status":"ok","timestamp":1651446627503,"user_tz":240,"elapsed":135,"user":{"displayName":"Pablo Amezquita","userId":"04689184241608460117"}},"outputId":"000a1f39-d8bd-42cf-b921-04c13d83e980"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/Colab Notebooks/CS584 HW4'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["# !pip uninstall tensorflow"],"metadata":{"id":"KIyNIiI8ud32","executionInfo":{"status":"ok","timestamp":1651423512282,"user_tz":240,"elapsed":3,"user":{"displayName":"Pablo Amezquita","userId":"04689184241608460117"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["!pip install tensorflow==2.4.0 #this is the version of tensorflow that I used. I was getting strange errors with tensorflow 2.8"],"metadata":{"id":"hYQ_NjpnvDhG","executionInfo":{"status":"ok","timestamp":1651423578471,"user_tz":240,"elapsed":65044,"user":{"displayName":"Pablo Amezquita","userId":"04689184241608460117"}},"colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"25080ed0-ff93-4d3f-daad-8410a7da79fb"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorflow==2.4.0\n","  Downloading tensorflow-2.4.0-cp37-cp37m-manylinux2010_x86_64.whl (394.7 MB)\n","\u001b[K     |████████████████████████████████| 394.7 MB 15 kB/s \n","\u001b[?25hRequirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (3.3.0)\n","Collecting h5py~=2.10.0\n","  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n","\u001b[K     |████████████████████████████████| 2.9 MB 94.7 MB/s \n","\u001b[?25hCollecting flatbuffers~=1.12.0\n","  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n","Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.6.3)\n","Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (3.17.3)\n","Collecting gast==0.3.3\n","  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n","Collecting typing-extensions~=3.7.4\n","  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n","Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (2.8.0)\n","Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (0.2.0)\n","Collecting wrapt~=1.12.1\n","  Downloading wrapt-1.12.1.tar.gz (27 kB)\n","Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (0.37.1)\n","Collecting grpcio~=1.32.0\n","  Downloading grpcio-1.32.0-cp37-cp37m-manylinux2014_x86_64.whl (3.8 MB)\n","\u001b[K     |████████████████████████████████| 3.8 MB 57.0 MB/s \n","\u001b[?25hRequirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.15.0)\n","Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.1.0)\n","Collecting absl-py~=0.10\n","  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n","\u001b[K     |████████████████████████████████| 132 kB 77.4 MB/s \n","\u001b[?25hRequirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.0) (1.1.2)\n","Collecting tensorflow-estimator<2.5.0,>=2.4.0rc0\n","  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n","\u001b[K     |████████████████████████████████| 462 kB 70.2 MB/s \n","\u001b[?25hCollecting numpy~=1.19.2\n","  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n","\u001b[K     |████████████████████████████████| 14.8 MB 57.7 MB/s \n","\u001b[?25hRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (0.6.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (1.8.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (0.4.6)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (2.23.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (3.3.6)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (1.35.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (57.4.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.0) (1.0.1)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (4.2.4)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (4.8)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.0) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.0) (4.11.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.0) (3.8.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (0.4.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (2021.10.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.0) (3.2.0)\n","Building wheels for collected packages: wrapt\n","  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=68715 sha256=79d449b8ff4771581aed323f5f7877595046946812a401eaffba634f259f485c\n","  Stored in directory: /root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n","Successfully built wrapt\n","Installing collected packages: typing-extensions, numpy, grpcio, absl-py, wrapt, tensorflow-estimator, h5py, gast, flatbuffers, tensorflow\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing-extensions 4.2.0\n","    Uninstalling typing-extensions-4.2.0:\n","      Successfully uninstalled typing-extensions-4.2.0\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.21.6\n","    Uninstalling numpy-1.21.6:\n","      Successfully uninstalled numpy-1.21.6\n","  Attempting uninstall: grpcio\n","    Found existing installation: grpcio 1.44.0\n","    Uninstalling grpcio-1.44.0:\n","      Successfully uninstalled grpcio-1.44.0\n","  Attempting uninstall: absl-py\n","    Found existing installation: absl-py 1.0.0\n","    Uninstalling absl-py-1.0.0:\n","      Successfully uninstalled absl-py-1.0.0\n","  Attempting uninstall: wrapt\n","    Found existing installation: wrapt 1.14.0\n","    Uninstalling wrapt-1.14.0:\n","      Successfully uninstalled wrapt-1.14.0\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.8.0\n","    Uninstalling tensorflow-estimator-2.8.0:\n","      Successfully uninstalled tensorflow-estimator-2.8.0\n","  Attempting uninstall: h5py\n","    Found existing installation: h5py 3.1.0\n","    Uninstalling h5py-3.1.0:\n","      Successfully uninstalled h5py-3.1.0\n","  Attempting uninstall: gast\n","    Found existing installation: gast 0.5.3\n","    Uninstalling gast-0.5.3:\n","      Successfully uninstalled gast-0.5.3\n","  Attempting uninstall: flatbuffers\n","    Found existing installation: flatbuffers 2.0\n","    Uninstalling flatbuffers-2.0:\n","      Successfully uninstalled flatbuffers-2.0\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.8.0\n","    Uninstalling tensorflow-2.8.0:\n","      Successfully uninstalled tensorflow-2.8.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed absl-py-0.15.0 flatbuffers-1.12 gast-0.3.3 grpcio-1.32.0 h5py-2.10.0 numpy-1.19.5 tensorflow-2.4.0 tensorflow-estimator-2.4.0 typing-extensions-3.7.4.3 wrapt-1.12.1\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]}}},"metadata":{}}]},{"cell_type":"code","source":["!pip install numpy==1.19.5"],"metadata":{"id":"ruoBKxhjzk4J","executionInfo":{"status":"ok","timestamp":1651423606745,"user_tz":240,"elapsed":2681,"user":{"displayName":"Pablo Amezquita","userId":"04689184241608460117"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"99c62323-1b08-4bf8-df4f-319950366fe2"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: numpy==1.19.5 in /usr/local/lib/python3.7/dist-packages (1.19.5)\n"]}]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"TRf675gXiD1f","outputId":"41165812-4a22-47c2-9d53-c3b1ec4e87dd","executionInfo":{"status":"ok","timestamp":1651446604381,"user_tz":240,"elapsed":45181,"user":{"displayName":"Pablo Amezquita","userId":"04689184241608460117"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.6)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.64.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.1.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.4.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.8)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib) (4.2.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n","Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n","Collecting spacy\n","  Downloading spacy-3.3.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n","\u001b[K     |████████████████████████████████| 6.2 MB 4.6 MB/s \n","\u001b[?25hCollecting spacy-legacy<3.1.0,>=3.0.9\n","  Downloading spacy_legacy-3.0.9-py2.py3-none-any.whl (20 kB)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.21.6)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n","Collecting pathy>=0.3.5\n","  Downloading pathy-0.6.1-py3-none-any.whl (42 kB)\n","\u001b[K     |████████████████████████████████| 42 kB 1.2 MB/s \n","\u001b[?25hRequirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.9.1)\n","Collecting catalogue<2.1.0,>=2.0.6\n","  Downloading catalogue-2.0.7-py3-none-any.whl (17 kB)\n","Collecting langcodes<4.0.0,>=3.2.0\n","  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n","\u001b[K     |████████████████████████████████| 181 kB 61.6 MB/s \n","\u001b[?25hCollecting srsly<3.0.0,>=2.4.3\n","  Downloading srsly-2.4.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (457 kB)\n","\u001b[K     |████████████████████████████████| 457 kB 64.9 MB/s \n","\u001b[?25hCollecting thinc<8.1.0,>=8.0.14\n","  Downloading thinc-8.0.15-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (653 kB)\n","\u001b[K     |████████████████████████████████| 653 kB 52.5 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.64.0)\n","Collecting typer<0.5.0,>=0.3.0\n","  Downloading typer-0.4.1-py3-none-any.whl (27 kB)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.6)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (21.3)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n","Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n","  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n","\u001b[K     |████████████████████████████████| 10.1 MB 41.7 MB/s \n","\u001b[?25hCollecting spacy-loggers<2.0.0,>=1.0.0\n","  Downloading spacy_loggers-1.0.2-py3-none-any.whl (7.2 kB)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.7)\n","Collecting typing-extensions<4.0.0.0,>=3.7.4\n","  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.8.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (3.0.8)\n","Collecting smart-open<6.0.0,>=5.0.0\n","  Downloading smart_open-5.2.1-py3-none-any.whl (58 kB)\n","\u001b[K     |████████████████████████████████| 58 kB 5.6 MB/s \n","\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n","Installing collected packages: typing-extensions, catalogue, typer, srsly, smart-open, pydantic, thinc, spacy-loggers, spacy-legacy, pathy, langcodes, spacy\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing-extensions 4.2.0\n","    Uninstalling typing-extensions-4.2.0:\n","      Successfully uninstalled typing-extensions-4.2.0\n","  Attempting uninstall: catalogue\n","    Found existing installation: catalogue 1.0.0\n","    Uninstalling catalogue-1.0.0:\n","      Successfully uninstalled catalogue-1.0.0\n","  Attempting uninstall: srsly\n","    Found existing installation: srsly 1.0.5\n","    Uninstalling srsly-1.0.5:\n","      Successfully uninstalled srsly-1.0.5\n","  Attempting uninstall: smart-open\n","    Found existing installation: smart-open 6.0.0\n","    Uninstalling smart-open-6.0.0:\n","      Successfully uninstalled smart-open-6.0.0\n","  Attempting uninstall: thinc\n","    Found existing installation: thinc 7.4.0\n","    Uninstalling thinc-7.4.0:\n","      Successfully uninstalled thinc-7.4.0\n","  Attempting uninstall: spacy\n","    Found existing installation: spacy 2.2.4\n","    Uninstalling spacy-2.2.4:\n","      Successfully uninstalled spacy-2.2.4\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\u001b[0m\n","Successfully installed catalogue-2.0.7 langcodes-3.3.0 pathy-0.6.1 pydantic-1.8.2 smart-open-5.2.1 spacy-3.3.0 spacy-legacy-3.0.9 spacy-loggers-1.0.2 srsly-2.4.3 thinc-8.0.15 typer-0.4.1 typing-extensions-3.10.0.2\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["catalogue","spacy","srsly","thinc","typing_extensions"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Collecting en-core-web-sm==3.3.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.3.0/en_core_web_sm-3.3.0-py3-none-any.whl (12.8 MB)\n","\u001b[K     |████████████████████████████████| 12.8 MB 4.7 MB/s \n","\u001b[?25hRequirement already satisfied: spacy<3.4.0,>=3.3.0.dev0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-sm==3.3.0) (3.3.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.64.0)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.7)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.6)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.8.2)\n","Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.10.0.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.11.3)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (21.3)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.6.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (57.4.0)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.3.0)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.7)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.4.3)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.2)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.6)\n","Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.4.1)\n","Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.9.1)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.23.0)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.9)\n","Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (8.0.15)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.4.1)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.21.6)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.8.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.8)\n","Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (5.2.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.10)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.1)\n","Installing collected packages: en-core-web-sm\n","  Attempting uninstall: en-core-web-sm\n","    Found existing installation: en-core-web-sm 2.2.5\n","    Uninstalling en-core-web-sm-2.2.5:\n","      Successfully uninstalled en-core-web-sm-2.2.5\n","Successfully installed en-core-web-sm-3.3.0\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_sm')\n","Collecting es-core-news-sm==3.3.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.3.0/es_core_news_sm-3.3.0-py3-none-any.whl (12.9 MB)\n","\u001b[K     |████████████████████████████████| 12.9 MB 5.2 MB/s \n","\u001b[?25hRequirement already satisfied: spacy<3.4.0,>=3.3.0.dev0 in /usr/local/lib/python3.7/dist-packages (from es-core-news-sm==3.3.0) (3.3.0)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (2.0.7)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (0.4.1)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (2.0.6)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (2.11.3)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (3.3.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (4.64.0)\n","Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (8.0.15)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (3.0.6)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (2.4.3)\n","Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (0.9.1)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (2.23.0)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (1.8.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (57.4.0)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (3.0.9)\n","Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (3.10.0.2)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (1.21.6)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (21.3)\n","Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (0.4.1)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (1.0.2)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (0.6.1)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (1.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (3.8.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (3.0.8)\n","Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (5.2.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (2.10)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (7.1.2)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.4.0,>=3.3.0.dev0->es-core-news-sm==3.3.0) (2.0.1)\n","Installing collected packages: es-core-news-sm\n","Successfully installed es-core-news-sm-3.3.0\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('es_core_news_sm')\n"]}],"source":["!pip install numpy scikit-learn tqdm matplotlib\n","!pip install -U spacy\n","!python -m spacy download en_core_web_sm\n","!python -m spacy download es_core_news_sm"]},{"cell_type":"code","source":["import tensorflow as tf\n","tf.__version__"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"kgp1FBfJvRXi","executionInfo":{"status":"ok","timestamp":1651446411235,"user_tz":240,"elapsed":3526,"user":{"displayName":"Pablo Amezquita","userId":"04689184241608460117"}},"outputId":"1b722edd-0ad5-4e83-81d1-cb791d29159e"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.8.0'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"joOGNC40iD1h"},"source":["# 1. Data Process\n","In this section, you are required to \n","1. Divide the data into train, validation, and test.\n","2. Preprocess the text data\n","\n","**Note:** The default dataset is for Spanish-English. Feel free to change other pairs of languages, you can find them [here](http://www.statmt.org/europarl/)."]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":115,"referenced_widgets":["172eff5d21204ae68115f5401e064b2b","4f54c2fd1d174b108e55cec207634ceb","a37daf1d9dba457c891016d3db4a1210","7ff836633b6348199a339053cab2ae45","eaaed0ca7b794ed7817bc12e7e1d87fb","5e48c23a90e24298afd9468b8458aecd","69b77f74cd364aaa9e9accfd583c404c","62baa95a4c3e4a8bbe9534ccd4d22bc4","58a8c8dd878f4af5a29ef4f601223f4d","23c83ab6a7c44add90b235c28ca98817","dca1817cbc4c450dac2b2fffb107a574","d4d12332c04c415ab7c5eb159a95344b","55e9b0cca5164ef5b6ca9d63c7078c44","3466945006b3461992b88aca898ed29a","bbf7c76eeda240a3a0aaee74aed7fd5e","ba8f6a746a7a4d328c64b8f7a2f7f4f3","b00429aed6bc43d79dcb029cf19bd4e0","3c62aaeb3d17419686d361746ad60288","7d72f7e185e942728799ed9a92320116","e3dd2e64e301461dae801fd32480b98d","5305b71cbef5486cb26ab296aabd9939","f212df33859a45f0ad5c2c79cf688d9d"]},"id":"Fg0l4AHMiD1h","outputId":"bcc1ee40-664f-495b-9fcf-8a8c5708006b","executionInfo":{"status":"ok","timestamp":1651446648645,"user_tz":240,"elapsed":15321,"user":{"displayName":"Pablo Amezquita","userId":"04689184241608460117"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2249121 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"172eff5d21204ae68115f5401e064b2b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2249121 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4d12332c04c415ab7c5eb159a95344b"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["English sentences size: (20000,)\n","French sentences size: (20000,)\n"]}],"source":["import numpy as np\n","from tqdm.notebook import tqdm\n","\n","def load_data(filepath):\n","    texts = []\n","    with open(filepath, 'r', encoding='utf-8') as f:\n","        count = len(f.readlines())\n","        \n","    with open(filepath, 'r', encoding='utf-8') as f:\n","        for line in tqdm(f, total=count):\n","            texts.append(line.strip())\n","            \n","    return np.array(texts[:20000])\n","\n","sources = load_data('training.en') #changed path to my files\n","targets = load_data('training.fr') #changed path to my files\n","\n","print('English sentences size:', sources.shape)\n","print('French sentences size:', targets.shape)"]},{"cell_type":"markdown","metadata":{"id":"cEy13GCHiD1h"},"source":["## 1.1 Divide the data into train, validation, and test"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xAeG4RU-iD1i","outputId":"62bef7d8-5fd4-448c-a320-6eae63c34807","executionInfo":{"status":"ok","timestamp":1651446649306,"user_tz":240,"elapsed":666,"user":{"displayName":"Pablo Amezquita","userId":"04689184241608460117"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["The size of training set: 12800\n","The size of valid set: 3200\n","The size of test set: 4000\n"]}],"source":["from sklearn.model_selection import train_test_split\n","\n","source_train, source_test, target_train, target_test = train_test_split(sources, targets, test_size=0.2)\n","source_train, source_valid, target_train, target_valid = train_test_split(source_train, target_train, test_size=0.2)\n","\n","train_texts = [(sent_source, sent_target) for sent_source, sent_target in zip(source_train, target_train)]\n","valid_texts = [(sent_source, sent_target) for sent_source, sent_target in zip(source_valid, target_valid)]\n","test_texts = [(sent_source, sent_target) for sent_source, sent_target in zip(source_test, target_test)]\n","\n","print('The size of training set:', len(train_texts))\n","print('The size of valid set:', len(valid_texts))\n","print('The size of test set:', len(test_texts))"]},{"cell_type":"markdown","metadata":{"id":"FRo90LeuiD1j"},"source":["## 1.2 Data preprocessing\n","1. Lowercase the text\n","2. Tokenize the text\n","3. Create vocabulary for the source language and target language, respectively."]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":115,"referenced_widgets":["c844be712c194aa29028e1d763789c78","d477aa8d619e4b7bb037306623bd19a3","5e865093350c419886aa43863204df14","b1bcfd5ce0514247b94e61f6581c2141","2b7e0bd0c45e4c8fad601c2a3bc0e42c","efc9c6fc771b4fc4bc3e94271f8d4fe8","7c67a1bef5b44e378afe9d826101dc71","2a9ef160c5c84156a1f46fae7e994b51","adfa4e45e2be408194a8e44475692604","da56f0a489ce4e94b9d0888c5fd00ed7","a0caa12f86fa409b9e2c52dda8df05e2","11b101e25cd04e9f9cc3d39defab8dff","79b9af8359ba4c9bb2030d19a636320d","62569de5a23c43f9baa3f5650caba26c","b292e07034454c859c129ca07b4bc0fe","3bf82d5c762648e3b2523a7ac5e280a9","88b05119cfd94151913df6cca1c00f0f","2cc8740da09f40c68da52c1c832c2b97","c30c4bf4de5a47e6973fc563346871f2","9f9b383f451045e383035cf6eb5e5753","b6f0941727ee4833822ced7391b30a8d","02007b5dc3fd4399bf189e996caa65e9"]},"id":"Grc2W2SCiD1k","outputId":"687c6cbf-b409-4c90-e991-21d16544197d","executionInfo":{"status":"ok","timestamp":1651446956758,"user_tz":240,"elapsed":307455,"user":{"displayName":"Pablo Amezquita","userId":"04689184241608460117"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["en:   0%|          | 0/12800 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c844be712c194aa29028e1d763789c78"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["es:   0%|          | 0/12800 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11b101e25cd04e9f9cc3d39defab8dff"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["English vocab size: 15585\n","French vocab size: 19712\n"]}],"source":["import re\n","import string\n","import spacy\n","from itertools import chain\n","from unicodedata import normalize, category\n","\n","nlp_en = spacy.load('en_core_web_sm')\n","nlp_es = spacy.load('es_core_news_sm')\n","\n","def tokenize_en(text):\n","    # text = re.sub(r'’', '\\'', text) # some of texts contain invalid apostrophes, such as ’\n","    # text = normalize('NFD', text).encode('ascii', 'ignore').decode('UTF-8')\n","    # text = re.sub(r'([.!.?])', r' \\1', text)\n","    # text = re.sub(r'[^a-zA-Z-]', r' ', text)\n","    # tokens = text.lower().strip().split()\n","    doc = nlp_en(text.lower())\n","    return [token.text for token in doc]\n","    # return tokens\n","\n","def tokenize_es(text):\n","    doc = nlp_es(text.lower())\n","    return [token.text for token in doc]\n","\n","def preprocess(texts, type='en'):\n","    if type == 'en':\n","        return [tokenize_en(text) for text in tqdm(texts, desc='en')]\n","    elif type == 'es':\n","        return [tokenize_es(text) for text in tqdm(texts, desc='es')]\n","\n","def generate_vocab(tokenized_texts):\n","    # Flatten the input to 1d array, Thanks for: \n","    # https://stackoverflow.com/questions/29244286/how-to-flatten-a-2d-list-to-1d-without-using-numpy\n","    vocab = list(chain.from_iterable(tokenized_texts))\n","    return list(set(vocab))\n","\n","source_tokens = preprocess(source_train, 'en')\n","target_tokens = preprocess(target_train, 'es')\n","\n","source_vocab = generate_vocab(source_tokens)\n","source_vocab.insert(0, '<unk>')\n","source_token2idx = {token: idx for idx, token in enumerate(source_vocab)}\n","\n","target_vocab = generate_vocab(target_tokens)\n","target_vocab.insert(0, '<end>')\n","target_vocab.insert(0, '<start>')\n","target_vocab.insert(0, '<unk>')\n","target_token2idx = {token: idx for idx, token in enumerate(target_vocab)}\n","\n","print('English vocab size:', len(source_vocab))\n","print('French vocab size:', len(target_vocab))"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"46ue6rX0iD1l","executionInfo":{"status":"ok","timestamp":1651447351866,"user_tz":240,"elapsed":395120,"user":{"displayName":"Pablo Amezquita","userId":"04689184241608460117"}}},"outputs":[],"source":["train_set = [([source_token2idx[t] for t in tokenize_en(source)], [target_token2idx[t] for t in tokenize_es(target)]) for source, target in train_texts]\n","valid_set = [([source_token2idx[t] if t in source_token2idx else 0 for t in tokenize_en(source)], [target_token2idx[t] if t in target_token2idx else 0 for t in tokenize_es(target)]) for source, target in valid_texts]\n","test_set = [([source_token2idx[t] if t in source_token2idx else 0 for t in tokenize_en(source)], [target_token2idx[t] if t in target_token2idx else 0 for t in tokenize_es(target)]) for source, target in test_texts]\n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z8D6tg5RO3Ft","executionInfo":{"status":"ok","timestamp":1651447351867,"user_tz":240,"elapsed":15,"user":{"displayName":"Pablo Amezquita","userId":"04689184241608460117"}},"outputId":"82972af7-105a-4a20-fbc0-0a49a2e7b657"},"outputs":[{"output_type":"stream","name":"stdout","text":["['<unk>', 'operate', 'ball', 'деп', 'merusak', 'to', 'asked', 'inec', 'regeneration', 'itself', 'austria', 'tempus', 'utilities', 'spill', 'pessoa', 'morals', 'painkillers', 'confiscation', 'haste', 'macedonian']\n","['<unk>', '<start>', '<end>', 'photographies', 'locaux', 'tempus', 'alloue', 'téléphone', 'accroissement', 'parlant', 'indien', 'porte-conteneurs', 'influencer', 'warren', 'veut', 'appellerons', 'légitimer', 'roll', 'éventuels', 'pesticides']\n"]}],"source":["#check what the vocab looks like\n","print(source_vocab[:20])\n","print(target_vocab[:20])"]},{"cell_type":"markdown","metadata":{"id":"x1IuruFjiD1l"},"source":["## 2. Seq2Seq Model (50 points)\n","In this section, you are required to \n","1. Implement a seq2seq model which includes a CNN encoder and an RNN based decoder.  \n","2. For each RNN cell, try a simple RNN, LSTM, and GRU.  \n","3. Use the validation set to compute the BLEU score and report the best choice.\n","\n","**Note:** you could use any package you are comfortable with, such as PyTorch and TensorFlow."]},{"cell_type":"markdown","metadata":{"id":"IRkI51oIiD1m"},"source":["### 2.1 Encoder (25 points)\n","\n","Try a simple RNN, LSTM, and GRU"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"QDih0oTfiD1n","executionInfo":{"status":"ok","timestamp":1651447366671,"user_tz":240,"elapsed":911,"user":{"displayName":"Pablo Amezquita","userId":"04689184241608460117"}}},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras import layers\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","import matplotlib.pyplot as plt \n","from nltk.translate.bleu_score import sentence_bleu"]},{"cell_type":"code","source":["np.__version__"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"lXirMcbZzDLK","executionInfo":{"status":"ok","timestamp":1651424413699,"user_tz":240,"elapsed":755,"user":{"displayName":"Pablo Amezquita","userId":"04689184241608460117"}},"outputId":"9beac6d5-25e7-47a4-9c9d-a86276633cdd"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'1.19.5'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":11}]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4sWWwuT3O3Fv","executionInfo":{"status":"ok","timestamp":1651424416796,"user_tz":240,"elapsed":338,"user":{"displayName":"Pablo Amezquita","userId":"04689184241608460117"}},"outputId":"ac67a504-9154-4a80-cf29-d45fda5baca9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Num GPUs Available:  1\n","[name: \"/device:CPU:0\"\n","device_type: \"CPU\"\n","memory_limit: 268435456\n","locality {\n","}\n","incarnation: 5327963622875617912\n",", name: \"/device:GPU:0\"\n","device_type: \"GPU\"\n","memory_limit: 14619084096\n","locality {\n","  bus_id: 1\n","  links {\n","  }\n","}\n","incarnation: 444154873461386751\n","physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n","]\n"]}],"source":["print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n","from tensorflow.python.client import device_lib\n","print(device_lib.list_local_devices())"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"K4QSGaoGO3Fw","executionInfo":{"status":"ok","timestamp":1651448107788,"user_tz":240,"elapsed":125,"user":{"displayName":"Pablo Amezquita","userId":"04689184241608460117"}}},"outputs":[],"source":["source_vocab_size = len(source_vocab)\n","target_vocab_size = len(target_vocab)\n","embedding_size = 300 #size of the embedding layer\n","hidden_size = 300 #size of the hidden layer"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OJMskswzO3Fw","executionInfo":{"status":"ok","timestamp":1651448110645,"user_tz":240,"elapsed":991,"user":{"displayName":"Pablo Amezquita","userId":"04689184241608460117"}},"outputId":"589d636e-38fc-4bc5-e99f-ee49ef7aa524"},"outputs":[{"output_type":"stream","name":"stdout","text":["[<KerasTensor: shape=(None, 300) dtype=float32 (created by layer 'simple_rnn')>]\n"]}],"source":["#simple RNN\n","simple_RNN_inputs = layers.Input(shape=(None,)) #The input layer of the encoder. Takes in a sentence in english tokenized\n","simple_RNN_embedding = layers.Embedding(input_dim=source_vocab_size, output_dim=embedding_size) #add an embedding layer to help get better results\n","simple_RNN_embedding_with_Inputs = simple_RNN_embedding(simple_RNN_inputs) #Apply the embedding layer to the inputs\n","simple_RNN_encoder = layers.SimpleRNN(hidden_size, return_state=True, dropout=0.25) #add a simpleRNN layer. This is the part that changes in each model\n","encoder_outputs, encoder_context_vector = simple_RNN_encoder(simple_RNN_embedding_with_Inputs)#apply the simpleRNN layer to the embedding layer output\n","simple_RNN_encoder_states = [encoder_context_vector]#the result of the encoder in list form\n","\n","print((simple_RNN_encoder_states))"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pC1kp-4tO3Fx","executionInfo":{"status":"ok","timestamp":1651424782243,"user_tz":240,"elapsed":910,"user":{"displayName":"Pablo Amezquita","userId":"04689184241608460117"}},"outputId":"b243da6f-d303-4e50-ef60-d3e9c9ee6100"},"outputs":[{"output_type":"stream","name":"stdout","text":["[<KerasTensor: shape=(None, 300) dtype=float32 (created by layer 'lstm')>, <KerasTensor: shape=(None, 300) dtype=float32 (created by layer 'lstm')>]\n"]}],"source":["#LSTM\n","lstm_inputs = layers.Input(shape=(None,))#The input layer of the encoder. Takes in a sentence in english tokenized\n","lstm_embedding =layers.Embedding(input_dim=source_vocab_size, output_dim=embedding_size)#add an embedding layer to help get better results\n","lstm_embedding_with_inputs = lstm_embedding(lstm_inputs)#Apply the embedding layer to the inputs\n","lstm_encoder = layers.LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.25) #add a LSTM layer\n","_, lstm_state_h, lstm_state_c = lstm_encoder(lstm_embedding_with_inputs)#apply the LSTM layer to the embedding layer and store the hidden state and cell state\n","lstm_encoder_states = [lstm_state_h, lstm_state_c]#set the hidden state and cell states as the encoder output\n","\n","print(lstm_encoder_states)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vWyecvk9O3Fx","executionInfo":{"status":"ok","timestamp":1650415086870,"user_tz":240,"elapsed":282,"user":{"displayName":"Pablo Amezquita","userId":"04689184241608460117"}},"outputId":"1234c664-95fc-4660-c0a1-5461bba748dc"},"outputs":[{"output_type":"stream","name":"stdout","text":["[<KerasTensor: shape=(None, 300) dtype=float32 (created by layer 'gru')>]\n"]}],"source":["#GRU\n","gru_inputs = layers.Input(shape=(None,))#The input layer of the encoder. Takes in a sentence in english tokenized\n","gru_embedding =layers.Embedding(input_dim=source_vocab_size, output_dim=embedding_size)#add an embedding layer to help get better results\n","gru_embedding_with_inputs = gru_embedding(gru_inputs)#Apply the embedding layer to the inputs\n","gru_encoder = layers.GRU(hidden_size, return_state=True, dropout=0.25)#Add a GRU layer.\n","_, gru_context_vec = gru_encoder(gru_embedding_with_inputs)#Apply the GRU layer to the embedding layer\n","gru_encoder_states = [gru_context_vec]#save the context vec output as a list\n","\n","print(gru_encoder_states)"]},{"cell_type":"markdown","metadata":{"id":"xjwALQhSTYZK"},"source":["### 2.2 CNN Encoder (Extra Credit)\n","\n","A traditional encoder of Seq2Seq models is an RNN-based model, such as RNN, LSTM, or GRU. But CNNs can also be encoders. In this sub-section, you need to implement a CNN encoder for your Seq2Seq model.\n","\n","**Hint:** We already learned how CNN can be applied to sentence classification tasks. You can simply drop the last layer of TextCNN and output the context vector. Please check this [paper](https://arxiv.org/abs/1510.03820) for details."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DdKJCEpCTf1Z"},"outputs":[],"source":["#I will attempt later"]},{"cell_type":"markdown","metadata":{"id":"ss-VG5vNiD1n"},"source":["### 2.3 Decoder (25 points)\n","Try a simple RNN, LSTM, and GRU"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"Fd8la5tdiD1n","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651424788225,"user_tz":240,"elapsed":639,"user":{"displayName":"Pablo Amezquita","userId":"04689184241608460117"}},"outputId":"6721c40a-2892-4b72-ecf5-0de4e6c707c3"},"outputs":[{"output_type":"stream","name":"stdout","text":["KerasTensor(type_spec=TensorSpec(shape=(None, None, 19368), dtype=tf.float32, name=None), name='dense_1/truediv:0', description=\"created by layer 'dense_1'\")\n"]}],"source":["#LSTM Decoder\n","lstm_decoder_input = layers.Input(shape=(None,))#The input layer of the decoder. It takes in the translated sentence with a start token and the sentence tokenized\n","lstm_decoder_embedding = layers.Embedding(input_dim=target_vocab_size, output_dim=embedding_size)#add an embedding layer\n","lstm_decoder_embedding_with_Inputs = lstm_decoder_embedding(lstm_decoder_input)#apply the embedding layer to the input layer\n","lstm_decoder = layers.LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.25)#add an lstm layer and return sequences is true, since we want the predictions at each timestep\n","lstm_decoder_outputs, _, _ = lstm_decoder(lstm_decoder_embedding_with_Inputs, initial_state=lstm_encoder_states)#apply the lstm layer to the embedding layer and set the initial state as the encoder context vector\n","lstm_dense = layers.Dense(target_vocab_size, activation=\"softmax\")#finally add a dense layer with softmax prediction function to predict the probabilities for each word\n","lstm_decoder_outputs = lstm_dense(lstm_decoder_outputs)#apply the dense layer to the output of the lstm layer\n","\n","print(lstm_decoder_outputs)"]},{"cell_type":"code","source":["#simpleRNN Decoder\n","simpleRNN_decoder_input = layers.Input(shape=(None,))#The input layer of the decoder. It takes in the translated sentence with a start token and the sentence tokenized\n","simpleRNN_decoder_embedding = layers.Embedding(input_dim=target_vocab_size, output_dim=embedding_size)#add embedding layer\n","simpleRNN_decoder_embedding_with_Inputs = simpleRNN_decoder_embedding(simpleRNN_decoder_input)#apply embedding layer to input layer\n","simpleRNN_decoder = layers.SimpleRNN(hidden_size, return_sequences=True, return_state=True, dropout=0.25)#add simpleRNN layer and return sequences is true since we want the predictions at each timestep\n","simpleRNN_decoder_outputs, _ = simpleRNN_decoder(simpleRNN_decoder_embedding_with_Inputs, initial_state=simple_RNN_encoder_states)#apply the simpleRNN layer to the embedding layer and set the initial state as the context vector from the encoder\n","simpleRNN_dense = layers.Dense(target_vocab_size, activation=\"softmax\")#add a dense layer with activaiton function as softmax\n","simpleRNN_decoder_outputs = simpleRNN_dense(simpleRNN_decoder_outputs)#appy the dense layer to the simpleRNN layer\n","\n","print(simpleRNN_decoder_outputs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-BTuYuXWkJQm","executionInfo":{"status":"ok","timestamp":1651448115544,"user_tz":240,"elapsed":482,"user":{"displayName":"Pablo Amezquita","userId":"04689184241608460117"}},"outputId":"41e86d74-2ceb-49e3-d903-684d414b8902"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["KerasTensor(type_spec=TensorSpec(shape=(None, None, 19712), dtype=tf.float32, name=None), name='dense/Softmax:0', description=\"created by layer 'dense'\")\n"]}]},{"cell_type":"code","source":["#GRU Decoder\n","gru_decoder_input = layers.Input(shape=(None,))#The input layer of the decoder. It takes in the translated sentence with a start token and the sentence tokenized\n","gru_decoder_embedding = layers.Embedding(input_dim=target_vocab_size, output_dim=embedding_size)#add embedding layer\n","gru_decoder_embedding_with_Inputs = gru_decoder_embedding(gru_decoder_input)#apply embedding layer to input layer\n","gru_decoder = layers.GRU(hidden_size, return_sequences=True, return_state=True, dropout=0.25)#add GRU layer with return sequences true to get predictions at each timestep\n","gru_decoder_outputs, _ = gru_decoder(gru_decoder_embedding_with_Inputs, initial_state=gru_encoder_states)#apply GRU layer to embedding layer and set the initial state as the context vecotr of the encoder\n","gru_dense = layers.Dense(target_vocab_size, activation=\"softmax\")#add dense layer with softmax activation function\n","gru_decoder_outputs = gru_dense(gru_decoder_outputs)#apply the dense layer to the GRU layer\n","\n","print(gru_decoder_outputs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xjUVnHaKkJjQ","executionInfo":{"status":"ok","timestamp":1650415087752,"user_tz":240,"elapsed":278,"user":{"displayName":"Pablo Amezquita","userId":"04689184241608460117"}},"outputId":"46eeb52f-1179-42b9-a201-9de3cdacad0d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["KerasTensor(type_spec=TensorSpec(shape=(None, None, 19620), dtype=tf.float32, name=None), name='dense_2/truediv:0', description=\"created by layer 'dense_2'\")\n"]}]},{"cell_type":"markdown","metadata":{"id":"LhN513adiD1o"},"source":["## 3. Training your Seq2Seq (30 points)\n","1. Implement training process\n","2. Use validation set to calculate BLEU score\n","3. Plot your training loss and validation loss (You could use the code in assignment 1)"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"qB8luI-JO3F0","executionInfo":{"status":"ok","timestamp":1651448138491,"user_tz":240,"elapsed":147,"user":{"displayName":"Pablo Amezquita","userId":"04689184241608460117"}}},"outputs":[],"source":["learning_rate = 0.001#set learning rate\n","batch_size = 64#set batch size\n","num_epochs = 15#set number of epochs"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"K3a49PIEO3F0","executionInfo":{"status":"ok","timestamp":1651447370868,"user_tz":240,"elapsed":573,"user":{"displayName":"Pablo Amezquita","userId":"04689184241608460117"}}},"outputs":[],"source":["#pad sentences so they are all the same length\n","\n","#get the max lengths of the target and the source texts for training, validation and test sets. \n","max_source_len_train = max([len(translation[0]) for translation in train_set])\n","max_target_len_train = max([len(translation[1]) for translation in train_set])\n","max_source_len_val = max([len(translation[0]) for translation in valid_set])\n","max_target_len_val = max([len(translation[1]) for translation in valid_set])\n","max_source_len_test = max([len(translation[0]) for translation in test_set])\n","max_target_len_test = max([len(translation[1]) for translation in test_set])\n","\n","#encoder input -> sentences in english\n","#decoder intput -> <START> sentence in target language\n","#decoder output -> sentence in target language <END>\n","\n","#get the encoder input, decoder input, and decoder output as outlined above for the training, test, and validation sets and pad them to the max lengths\n","encoder_input = [translation[0] for translation in train_set]\n","encoder_input = pad_sequences(encoder_input, maxlen=max_source_len_train, padding=\"post\")\n","decoder_input = [[target_token2idx[\"<start>\"]]+translation[1] for translation in train_set]\n","decoder_input = pad_sequences(decoder_input, maxlen=max_target_len_train+1, padding=\"post\")\n","decoder_output = [translation[1]+[target_token2idx[\"<end>\"]] for translation in train_set]\n","decoder_output = pad_sequences(decoder_output, maxlen=max_target_len_train+1, padding=\"post\")\n","\n","val_encoder_input = [translation[0] for translation in valid_set]\n","val_encoder_input = pad_sequences(val_encoder_input, maxlen=max_source_len_val, padding=\"post\")\n","val_decoder_input = [[target_token2idx[\"<start>\"]]+translation[1] for translation in valid_set]\n","val_decoder_input = pad_sequences(val_decoder_input, maxlen=max_target_len_val+1, padding=\"post\")\n","val_decoder_output = [translation[1]+[target_token2idx[\"<end>\"]] for translation in valid_set]\n","val_decoder_output = pad_sequences(val_decoder_output, maxlen=max_target_len_val+1, padding=\"post\")\n","\n","test_encoder_input = [translation[0] for translation in test_set]\n","test_encoder_input = pad_sequences(test_encoder_input, maxlen=max_source_len_test, padding=\"post\")\n","test_decoder_input = [[target_token2idx[\"<start>\"]]+translation[1] for translation in test_set]\n","test_decoder_input = pad_sequences(test_decoder_input, maxlen=max_target_len_test+1, padding=\"post\")\n","test_decoder_output = [translation[1]+[target_token2idx[\"<end>\"]] for translation in test_set]\n","test_decoder_output = pad_sequences(test_decoder_output, maxlen=max_target_len_test+1, padding=\"post\")"]},{"cell_type":"code","source":["print(encoder_input)\n","print(decoder_input.shape)\n","print(decoder_output.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h5ETAlLS7yYg","executionInfo":{"status":"ok","timestamp":1651448508697,"user_tz":240,"elapsed":171,"user":{"displayName":"Pablo Amezquita","userId":"04689184241608460117"}},"outputId":"5b457cc8-7a23-4a7c-e01c-7845c1893b79"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["[[ 3974  6015  9427 ...     0     0     0]\n"," [11680  2094  8172 ...     0     0     0]\n"," [ 2223 14111  5629 ...     0     0     0]\n"," ...\n"," [12586  8702   191 ...     0     0     0]\n"," [11735  9427 14341 ...     0     0     0]\n"," [ 6343 12595 14734 ...     0     0     0]]\n","(12800, 111)\n","(12800, 111)\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R0PNQS2LO3F1"},"outputs":[],"source":["#for testing purposes, use less data\n","# encoder_input = encoder_input[:5000]\n","# decoder_input = decoder_input[:5000]\n","# decoder_output = decoder_output[:5000]\n","\n","# val_encoder_input = val_encoder_input[:1250]\n","# val_decoder_input = val_decoder_input[:1250]\n","# val_decoder_output = val_decoder_output[:1250]"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":253},"id":"nTv-Fk4OiD1p","outputId":"fe060912-d85b-427a-c3a4-14c86815ef74","executionInfo":{"status":"error","timestamp":1651448124354,"user_tz":240,"elapsed":128,"user":{"displayName":"Pablo Amezquita","userId":"04689184241608460117"}}},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-a7f037bc4aba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#lstm training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlstm_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlstm_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm_decoder_input\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm_decoder_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#define the model LSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlstm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sparse_categorical_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#compile the model. Used Adam because that was what i used in hw 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'lstm_inputs' is not defined"]}],"source":["#lstm training\n","lstm_model = keras.models.Model([lstm_inputs, lstm_decoder_input], lstm_decoder_outputs)#define the model LSTM\n","\n","lstm_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate), metrics = ['accuracy'])#compile the model. Used Adam because that was what i used in hw 3\n","\n","lstm_model.summary()"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2DAtw52tO3F2","executionInfo":{"status":"ok","timestamp":1651425545500,"user_tz":240,"elapsed":748603,"user":{"displayName":"Pablo Amezquita","userId":"04689184241608460117"}},"outputId":"b2d1f152-3f93-4782-c4f0-34ae343df1b6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/15\n","200/200 [==============================] - 60s 239ms/step - loss: 3.9453 - accuracy: 0.6827 - val_loss: 1.8267 - val_accuracy: 0.7252\n","Epoch 2/15\n","200/200 [==============================] - 48s 240ms/step - loss: 1.8392 - accuracy: 0.7343 - val_loss: 1.6439 - val_accuracy: 0.7515\n","Epoch 3/15\n","200/200 [==============================] - 49s 244ms/step - loss: 1.6367 - accuracy: 0.7547 - val_loss: 1.5433 - val_accuracy: 0.7582\n","Epoch 4/15\n","200/200 [==============================] - 49s 246ms/step - loss: 1.5237 - accuracy: 0.7628 - val_loss: 1.4666 - val_accuracy: 0.7655\n","Epoch 5/15\n","200/200 [==============================] - 49s 246ms/step - loss: 1.4479 - accuracy: 0.7683 - val_loss: 1.4061 - val_accuracy: 0.7709\n","Epoch 6/15\n","200/200 [==============================] - 49s 247ms/step - loss: 1.3755 - accuracy: 0.7743 - val_loss: 1.3639 - val_accuracy: 0.7737\n","Epoch 7/15\n","200/200 [==============================] - 49s 247ms/step - loss: 1.3189 - accuracy: 0.7779 - val_loss: 1.3341 - val_accuracy: 0.7762\n","Epoch 8/15\n","200/200 [==============================] - 49s 247ms/step - loss: 1.2633 - accuracy: 0.7833 - val_loss: 1.3408 - val_accuracy: 0.7720\n","Epoch 9/15\n","200/200 [==============================] - 49s 247ms/step - loss: 1.2532 - accuracy: 0.7815 - val_loss: 1.3070 - val_accuracy: 0.7760\n","Epoch 10/15\n","200/200 [==============================] - 49s 247ms/step - loss: 1.2214 - accuracy: 0.7834 - val_loss: 1.2953 - val_accuracy: 0.7770\n","Epoch 11/15\n","200/200 [==============================] - 49s 247ms/step - loss: 1.1786 - accuracy: 0.7876 - val_loss: 1.2872 - val_accuracy: 0.7776\n","Epoch 12/15\n","200/200 [==============================] - 49s 247ms/step - loss: 1.1625 - accuracy: 0.7877 - val_loss: 1.2806 - val_accuracy: 0.7786\n","Epoch 13/15\n","200/200 [==============================] - 49s 247ms/step - loss: 1.1281 - accuracy: 0.7914 - val_loss: 1.2765 - val_accuracy: 0.7792\n","Epoch 14/15\n","200/200 [==============================] - 49s 247ms/step - loss: 1.0989 - accuracy: 0.7939 - val_loss: 1.2715 - val_accuracy: 0.7803\n","Epoch 15/15\n","200/200 [==============================] - 49s 247ms/step - loss: 1.0775 - accuracy: 0.7955 - val_loss: 1.2668 - val_accuracy: 0.7818\n"]}],"source":["#fit the model and save the history\n","lstm_hist = lstm_model.fit([encoder_input, decoder_input], \n","          decoder_output, epochs=num_epochs, \n","          batch_size=batch_size, \n","          validation_data=([val_encoder_input, val_decoder_input], val_decoder_output))"]},{"cell_type":"code","source":["#LSTM Plot\n","lstm_train_loss = lstm_hist.history[\"loss\"]\n","lstm_val_loss = lstm_hist.history[\"val_loss\"]\n","plt.plot(range(num_epochs), lstm_train_loss, lstm_val_loss)\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend([\"Training loss\", \"Validation loss\"])\n","plt.title('LSTM')\n","plt.show()"],"metadata":{"id":"7Nqyn81nhwNO","executionInfo":{"status":"ok","timestamp":1651425814499,"user_tz":240,"elapsed":1145,"user":{"displayName":"Pablo Amezquita","userId":"04689184241608460117"}},"colab":{"base_uri":"https://localhost:8080/","height":295},"outputId":"59833a04-90ed-410a-d42b-7eeb5a1e7466"},"execution_count":26,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["#SimpleRNN Training\n","simpleRNN_model = keras.models.Model([simple_RNN_inputs, simpleRNN_decoder_input], simpleRNN_decoder_outputs)#define the model simpleRNN\n","\n","simpleRNN_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate), metrics = ['accuracy'])#compile the model\n","\n","simpleRNN_model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OibfV8EVnVBa","executionInfo":{"status":"ok","timestamp":1651448145044,"user_tz":240,"elapsed":395,"user":{"displayName":"Pablo Amezquita","userId":"04689184241608460117"}},"outputId":"4f28f909-861b-4803-e516-128debda0339"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_1\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_2 (InputLayer)           [(None, None)]       0           []                               \n","                                                                                                  \n"," input_3 (InputLayer)           [(None, None)]       0           []                               \n","                                                                                                  \n"," embedding (Embedding)          (None, None, 300)    4675500     ['input_2[0][0]']                \n","                                                                                                  \n"," embedding_1 (Embedding)        (None, None, 300)    5913600     ['input_3[0][0]']                \n","                                                                                                  \n"," simple_rnn (SimpleRNN)         [(None, 300),        180300      ['embedding[0][0]']              \n","                                 (None, 300)]                                                     \n","                                                                                                  \n"," simple_rnn_1 (SimpleRNN)       [(None, None, 300),  180300      ['embedding_1[0][0]',            \n","                                 (None, 300)]                     'simple_rnn[0][1]']             \n","                                                                                                  \n"," dense (Dense)                  (None, None, 19712)  5933312     ['simple_rnn_1[0][0]']           \n","                                                                                                  \n","==================================================================================================\n","Total params: 16,883,012\n","Trainable params: 16,883,012\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["# np.asarray([encoder_input, decoder_input])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":342},"id":"o0vdTm-JkgK3","executionInfo":{"status":"error","timestamp":1651424528934,"user_tz":240,"elapsed":652,"user":{"displayName":"Pablo Amezquita","userId":"04689184241608460117"}},"outputId":"084a253c-e7d2-455f-d4e9-52707200f2a5"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  return array(a, dtype, copy=False, order=order)\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-68afcfdc06fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_input\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (12800,101) into shape (12800)"]}]},{"cell_type":"code","source":["#fit the model\n","simpleRNN_hist = simpleRNN_model.fit([encoder_input, decoder_input], \n","          decoder_output, epochs=num_epochs, \n","          batch_size=batch_size, \n","          validation_data=([val_encoder_input, val_decoder_input], val_decoder_output))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":364},"id":"51psy-BJol26","executionInfo":{"status":"error","timestamp":1651448167022,"user_tz":240,"elapsed":16041,"user":{"displayName":"Pablo Amezquita","userId":"04689184241608460117"}},"outputId":"dbcdc420-a413-435f-be8c-a86e634a9888"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/15\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-91a272c9c670>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0mdecoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m           validation_data=([val_encoder_input, val_decoder_input], val_decoder_output))\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    978\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 980\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    981\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["#SimpleRNN Plot\n","simpleRNN_train_loss = simpleRNN_hist.history[\"loss\"]\n","simpleRNN_val_loss = simpleRNN_hist.history[\"val_loss\"]\n","plt.plot(range(num_epochs), lstm_train_loss, lstm_val_loss)\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend([\"Training loss\", \"Validation loss\"])\n","plt.title('Simple RNN')\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"id":"mPLCBLcCo1Dh","executionInfo":{"status":"ok","timestamp":1650425731990,"user_tz":240,"elapsed":339,"user":{"displayName":"Pablo Amezquita","userId":"04689184241608460117"}},"outputId":"37da3093-4200-4078-df70-e5c2160a7821"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["#GRU Training\n","gru_model = keras.models.Model([gru_inputs, gru_decoder_input], gru_decoder_outputs)#define the model GRU\n","\n","gru_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate), metrics = ['accuracy'])#compile the model\n","\n","gru_model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hoxYYqZKpAAf","executionInfo":{"status":"ok","timestamp":1650425732185,"user_tz":240,"elapsed":202,"user":{"displayName":"Pablo Amezquita","userId":"04689184241608460117"}},"outputId":"f2a89244-00d6-445d-cd58-d37259671488"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_10\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_3 (InputLayer)            [(None, None)]       0                                            \n","__________________________________________________________________________________________________\n","input_6 (InputLayer)            [(None, None)]       0                                            \n","__________________________________________________________________________________________________\n","embedding_2 (Embedding)         (None, None, 300)    4678800     input_3[0][0]                    \n","__________________________________________________________________________________________________\n","embedding_5 (Embedding)         (None, None, 300)    5886000     input_6[0][0]                    \n","__________________________________________________________________________________________________\n","gru (GRU)                       [(None, 300), (None, 541800      embedding_2[0][0]                \n","__________________________________________________________________________________________________\n","gru_1 (GRU)                     [(None, None, 300),  541800      embedding_5[0][0]                \n","                                                                 gru[0][1]                        \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, None, 19620)  5905620     gru_1[0][0]                      \n","==================================================================================================\n","Total params: 17,554,020\n","Trainable params: 17,554,020\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["#fit the model\n","gru_hist = gru_model.fit([encoder_input, decoder_input], \n","          decoder_output, epochs=num_epochs, \n","          batch_size=batch_size, \n","          validation_data=([val_encoder_input, val_decoder_input], val_decoder_output))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GhdjbA5spSjO","executionInfo":{"status":"ok","timestamp":1650426354122,"user_tz":240,"elapsed":621946,"user":{"displayName":"Pablo Amezquita","userId":"04689184241608460117"}},"outputId":"25de85c6-0263-4dd8-93e8-2e89f3133a5b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/15\n","200/200 [==============================] - 45s 210ms/step - loss: 0.9649 - accuracy: 0.8037 - val_loss: 1.4560 - val_accuracy: 0.7728\n","Epoch 2/15\n","200/200 [==============================] - 41s 207ms/step - loss: 0.8915 - accuracy: 0.8125 - val_loss: 1.4720 - val_accuracy: 0.7733\n","Epoch 3/15\n","200/200 [==============================] - 41s 207ms/step - loss: 0.8622 - accuracy: 0.8169 - val_loss: 1.4821 - val_accuracy: 0.7736\n","Epoch 4/15\n","200/200 [==============================] - 41s 206ms/step - loss: 0.8209 - accuracy: 0.8236 - val_loss: 1.5067 - val_accuracy: 0.7737\n","Epoch 5/15\n","200/200 [==============================] - 41s 207ms/step - loss: 0.8076 - accuracy: 0.8246 - val_loss: 1.5173 - val_accuracy: 0.7739\n","Epoch 6/15\n","200/200 [==============================] - 41s 206ms/step - loss: 0.7674 - accuracy: 0.8319 - val_loss: 1.5296 - val_accuracy: 0.7741\n","Epoch 7/15\n","200/200 [==============================] - 41s 206ms/step - loss: 0.7510 - accuracy: 0.8343 - val_loss: 1.5462 - val_accuracy: 0.7744\n","Epoch 8/15\n","200/200 [==============================] - 41s 207ms/step - loss: 0.7319 - accuracy: 0.8371 - val_loss: 1.5593 - val_accuracy: 0.7743\n","Epoch 9/15\n","200/200 [==============================] - 41s 206ms/step - loss: 0.6987 - accuracy: 0.8432 - val_loss: 1.5711 - val_accuracy: 0.7743\n","Epoch 10/15\n","200/200 [==============================] - 41s 206ms/step - loss: 0.6780 - accuracy: 0.8467 - val_loss: 1.5859 - val_accuracy: 0.7742\n","Epoch 11/15\n","200/200 [==============================] - 41s 207ms/step - loss: 0.6544 - accuracy: 0.8514 - val_loss: 1.5988 - val_accuracy: 0.7740\n","Epoch 12/15\n","200/200 [==============================] - 41s 206ms/step - loss: 0.6435 - accuracy: 0.8526 - val_loss: 1.6099 - val_accuracy: 0.7745\n","Epoch 13/15\n","200/200 [==============================] - 41s 206ms/step - loss: 0.6262 - accuracy: 0.8559 - val_loss: 1.6222 - val_accuracy: 0.7737\n","Epoch 14/15\n","200/200 [==============================] - 41s 206ms/step - loss: 0.6051 - accuracy: 0.8600 - val_loss: 1.6372 - val_accuracy: 0.7740\n","Epoch 15/15\n","200/200 [==============================] - 41s 206ms/step - loss: 0.5903 - accuracy: 0.8630 - val_loss: 1.6481 - val_accuracy: 0.7736\n"]}]},{"cell_type":"code","source":["#GRU Plot\n","gru_train_loss = gru_hist.history[\"loss\"]\n","gru_val_loss = gru_hist.history[\"val_loss\"]\n","plt.plot(range(num_epochs), gru_train_loss, gru_val_loss)\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend([\"Training loss\", \"Validation loss\"])\n","plt.title('GRU')\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295},"id":"7j7tGhVBpZ65","executionInfo":{"status":"ok","timestamp":1650426357359,"user_tz":240,"elapsed":3253,"user":{"displayName":"Pablo Amezquita","userId":"04689184241608460117"}},"outputId":"2eb20b76-6908-43c3-c3a8-646b810381a8"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3xV1Z338c8v9/s9AZIQEsJNURAIWklVrJ2prY60jq3SPlXqVFunFy/T6djWtvY2rz4tM2N9RulQrWhrSy+2jLZa21oRFVtBRAQEhRBCgJAQQm5cclvPH3vn5ASSECAnJ8n5vl+v8zrn7HPJ70Cyvmetvfba5pxDREQiV1S4CxARkfBSEIiIRDgFgYhIhFMQiIhEOAWBiEiEUxCIiEQ4BYGISIRTEIicgpndYGZ/M7NWM6v1b/+zeVaYWZuZtZjZITP7k5nNCHrtvWb20z7e05nZlOH9JCJ9UxCIDMDM/gX4AfB9YDwwDvg0UA7E+U/7nnMuBSgA9gIPh6FUkTMWE+4CREYqM0sHvgnc6Jx7Iuih14GP+c8JbHTOHTWzXwK/Gs46Rc6WegQi/bsYiAf+dzBPNrNkYDGwI5RFiQw1BYFI/3KAg865ju4NZrbWzA6b2VEzu9Tf/AUzOww0A+8GPh6GWkXOmIJApH/1QI6ZBYZQnXMLnHMZ/mPdfz9L/W3FwFFgetB7dACxwW9qZt3320NUt8hpURCI9O8V4DiwaDBPds5VAbcDPzCzRH9zFV5ABCvBC4i9Q1OmyNlREIj0wzl3GPgG8KCZXWdmqWYWZWYXAMn9vOZPwD7gVn/TH4AZZvZxM4s1syzg34EngoecRMJJQSAyAOfc94C7gC8CB/zL/wD/Bqzt52XfB75oZvHOuVrg/cCngFpgM3AYuC3EpYsMmunENCIikU09AhGRCKcgEBGJcAoCEZEIpyAQEYlwo26toZycHFdcXBzuMkRERpXXXnvtoHMut6/HRl0QFBcXs379+nCXISIyqpjZ7v4e09CQiEiEUxCIiEQ4BYGISIRTEIiIRDgFgYhIhFMQiIhEOAWBiEiEG3XHEYiIjHmd7dBaBy0HoPmAd91SC4XzoPQ9Q/7jFAQiIsPBOTjW6DXoLQd6X4Ib+5YaOFLf93u8+04FgYjIiNTVCU17oaESGnZD076TG/uWWug4dvJro+MhZRyk5EFWCRRd5N8PvuR5l5j4kJSvIBARORXnoPUgHN7tN/aV/u3d3nVjNXSdcObRpOyeRrxogd+Yj4PU8T23U/IgIQPMwvGpAhQEIiIAx5t7GvaG3Sc09lXQ3tr7+cm5kFkMBWVw3j9CxiTInORdpxVATFw4PsUZURCIyNjX0eaNvTft94Zwmvd7wzeN1T2N/dFDvV8Tl+o17FmTvXH57kY+cxJkFEFccng+SwgoCERkdDvW1NOwN+2D5n1+gx90u7X25NfFJEJavtewT7ggqKEv9i6JmWEfshkuIQsCM/sxcDVQ65w7r5/nLATuA2KBg865y0JVj4iMMh1tXgPefMD/Nr/Pb/CDv9Xvh7bmk1+bmOU18qkTvEa++3ZaAaRN8O6PgLH5kSKUPYIVwH8Dj/X1oJllAA8CVzrnqswsL4S1iMhI4Bwcb/Jm0DTXBE2frOmZOtn92IlDNQAW7TfoEyB3BpRe4d1Ozfca97QJ3uOxicP/2UaxkAWBc26NmRUP8JSPAr9xzlX5z++j7yYio4JzcOQQNFX3fIMPzI0PatxbaqHj6Mmvj46DlPGQOs4bky+62J9hEzSFMi3f20EbFT38n2+MC+c+gmlArJmtBlKBHzjn+us93ArcClBUVDRsBYoIXiN/tMEbjunewdrX7b7myCdk9DToEy8Mmj4Z1MCnjtMwTZiFMwhigHnAFUAi8IqZ/dU59/aJT3TOLQeWA5SVlblhrVJkLOs+2vVUjXz7kd6v6x6iSS/wxuCnfwDSC/2x+HyvcU/Og9iE8HwuOS3hDIJqoN451wq0mtkaYDZwUhCIyBnqHrI5XNkzH757umR3Q9/W0vs1FuUN06Tlw7iZMPV9XoOflg9phd7tlHEaohlDwhkE/wv8t5nFAHHARcB/hbEekdHpWFPvA5+Cj3g9XHVyQ5+Y6c2Dz5kKpZd7M2nSC7xGPi3fG7qJjg3PZ5GwCOX00Z8DC4EcM6sGvo43TRTn3A+dc2+Z2R+ATUAX8JBzbnOo6hEZtdqPeg16oHE/oaE/2tD7+XEp3nz4jElQcmnvg6AyiiAhPTyfQ0asUM4aWjyI53wf+H6oahAZ0To7vKWGm/cHXWp6rpv8bSdOo4yO9xr0zEne8gbdt7sb/6Qs7XiV06Iji0WGWve4fKBh39e7ge8+EKq1FlxX79dalD+TZoJ3dGvRu7y58RlByxsk50GUziklQ0dBIHI6nPO+xXfvaG3c682db9zbc7Rrcw10tp382qRsr4FPHQ/jzuu53X2AVOoEzZOXsFAQiHQLnkrZWH1CY+9va9oHncd7vy463t/ZWuAdCNXduAcu471LiNaSFzlbCgKJHF1d3jBN/U5o3OM18I17ejf2J02l7J4vXwgFc+Gcf/DnywfNtEnO0Zi8jGoKAhlbnPOGZ+p3wqGd/nWFd92w6+SjX5PzvAY9Z6q31HD3N/vuxj51vIZqZMxTEMjo45w3Dn+oIqix3wn1Fd624LVsouMgswSyS2HKFd46Ntml/slD8jVcI4KCQEaqzg5vsbLDe/pu7IPPFhUV682wyS6FyQshe7LX4GeVet/s9Y1eZEAKAhl+x5v9OfL7gq739d524tTKqBjvW3x2KRS/27vO8hv89IkQrV9lkTOlvx4ZOl1d/gFSAzTwzfu99ehPlJDRc/KQcTP98fkJXiOfPRnSi9TYi4SI/rJkYM553+Bb6/wThxzwbx/w79d6395bar1Gvquj9+stumc6Ze40b22b1AlBZ4zyr+OSwvP5RERBELGOt/Q04Cc18HX+Y/7tvk4kYlGQlOOvKZ8L2VP91Snzgw6QyoeUPI3Ri4xwCoKxrv0Y1GyC6vWw9zXYv7Hv9eUBMG9OfHKe14AXTfaOdE0Z591Pyet5LClbDbzIGKEgGEu6uryZNdXrYa/f8Ndshq527/G0AsifA9OuDGrgc/3GfZzXuGscXiTi6K9+NGup8xr7veu9xn/fBm+JBPCWIs6fAws+CwXzvFUq0yaEt14RGZEUBKNF+1HY/4bX8Hd/4z9c5T1m0ZB3Lsz8kNfgF5ZBzjQN3YjIoCgIRpqONm+nbWstHNjaM8RzYEvPjJz0id63/Pm3eI3+hNkQlxzeukVk1FIQhJpz3rz51oP+VMu63peWWu+xVv+x7qGdbvFp3hBP+e3et/2Ced6JwUVEhoiC4Ex1r3fTsMtbnrjPRt6/PnHZ4m6Jmd5O2+Q8b336lDz/fo53nT3VH+LRSUhEJHQUBAPp7PCWKT5U4TX4h/xL9+0T59dHxfqzcXK969xzehr1lLyeqZndjb1OEC4iI4CCoP2odyLwXo29f/twVe8jZWMSvMXNsibD5Mshq8S7pBd5DX1CutalF5FRJ3KCoLkGdq89+Zt9097ez4tPh6xibwfsuR/0FzYr8ZYyTp2gYRoRGXMiJwiqXoFff8K7nZznNe4ll3oNfHBjn5Slb/UiElEiJwgmL4RPv+QN7cSnhrkYEZGRI3KCIDHTu4iISC8a8BYRiXAKAhGRCKcgEBGJcAoCEZEIpyAQEYlwIQsCM/uxmdWa2eZTPG++mXWY2XWhqkVERPoXyh7BCuDKgZ5gZtHA/wX+GMI6RERkACELAufcGuDQKZ72OeAJoDZUdYiIyMDCto/AzAqADwHLBvHcW81svZmtr6urC31xIiIRJJw7i+8D/s0513WqJzrnljvnypxzZbm5ucNQmohI5AjnEhNlwErzFnjLAT5gZh3OuVVhrElEJOKELQiccyXdt81sBfA7hYCIyPALWRCY2c+BhUCOmVUDXwdiAZxzPwzVzxURkdMTsiBwzi0+jecuCVUdIiIyMB1ZLCIS4RQEIiIRTkEgIhLhFAQiIhFOQSAiEuEUBCIiEU5BICIS4RQEIiIRTkEgIhLhFAQiIhFOQSAiEuEUBCIiEU5BICIS4RQEIiIRTkEgIhLhFAQiIhFOQSAiEuEUBCIiEU5BICIS4RQEIiIRTkEgIhLhFAQiIhFOQSAiEuEUBCIiEU5BICIS4RQEIiIRTkEgIhLhFAQiIhEuZEFgZj82s1oz29zP4x8zs01m9qaZrTWz2aGqRURE+hfKHsEK4MoBHt8FXOacOx/4FrA8hLWIiEg/YkL1xs65NWZWPMDja4Pu/hUoDFUtIiLSv5Gyj+CfgGfCXYSISCQKWY9gsMzscrwgePcAz7kVuBWgqKhomCoTEYkMYe0RmNks4CFgkXOuvr/nOeeWO+fKnHNlubm5w1egiEgECFsQmFkR8Bvg4865t8NVh4hIpAvZ0JCZ/RxYCOSYWTXwdSAWwDn3Q+BrQDbwoJkBdDjnykJVj4iI9C2Us4YWn+LxTwKfDNXPFxGRwRkps4ZERCRMBhUEZpZsZlH+7Wlmdo2ZxYa2NBERGQ6D7RGsARLMrAD4I/BxvCOHRURklBtsEJhz7ghwLfCgc+7DwMzQlSUiIsNl0EFgZhcDHwN+72+LDk1JIiIynAYbBHcAXwJ+65zbYmaTgedDV5aIiAyXQU0fdc69ALwA4O80Puic+3woCxMRkeEx2FlDPzOzNDNLBjYDW83sX0NbmoiIDIfBDg2d65xrAj6It0poCd7MIRERGeUGGwSx/nEDHwSedM61Ay50ZYmIyHAZbBD8D1AJJANrzGwS0BSqokREZPgMdmfx/cD9QZt2++cREBGRUW6wO4vTzew/zWy9f/kPvN6BiIiMcoMdGvox0Ax8xL80AY+EqigRERk+g12GutQ5949B979hZhtDUZCIiAyvwfYIjppZ4JzCZlYOHA1NSSIiMpwG2yP4NPCYmaX79xuAm0JTkoiIDKfBzhp6A5htZmn+/SYzuwPYFMriREQk9E7rDGXOuSb/CGOAu0JQj4iIDLOzOVWlDVkVIiISNmcTBFpiQkRkDBhwH4GZNdN3g29AYkgqEhGRYTVgEDjnUoerEBERCY+zGRoSEZExQEEgIhLhFAQiIhFOQSAiEuEUBCIiEU5BICIS4UIWBGb2YzOrNbPN/TxuZna/me0ws01mNjdUtYiISP9C2SNYAVw5wOPvB6b6l1uBZSGsRURE+hGyIHDOrQEODfCURcBjzvNXIMPMJoSqHhER6Vs49xEUAHuC7lf7205iZrd2ny+5rq5uWIoTEYkUo2JnsXNuuXOuzDlXlpubG+5yRETGlHAGwV5gYtD9Qn+biIgMo3AGwZPAjf7soXcBjc65/WGsR0QkIg32nMWnzcx+DiwEcsysGvg6EAvgnPsh8DTwAWAHcAT4RKhqERGR/oUsCJxzi0/xuAM+E6qfLyIigzMqdhaLiEjoRFQQeJ0QEREJFjFBsHlvIx+4/yWefGMfnV0KBBGRbhETBC3HO2jv7OLzP3+d9/zHan7+ahXHOzrDXZaISNjZaBsuKSsrc+vXrz+j13Z1Of649QDLVu/gjepGxqXF88l3T+ajFxWRHB+y/eYiImFnZq8558r6fCySgqCbc46Xd9Tz4OodrN1ZT0ZSLDddXMySBcVkJscNUaUiIiOHgmAAr1c18ODqnfxp6wGS4qL56IVFfPKSyYxPTxiynyEiEm4KgkHYXtPMD1/YyZNv7CPajH+cV8CnLi2lOCd5yH+WiMhwUxCchj2HjvA/a3byy/XVdHR2cdWsfG67rJRz89NC9jNFREJNQXAGapuP8fBLu/jpK7tpbevkPTPy+OeFpZQVZ4X8Z4uIDDUFwVloPNLOY69U8sjaSg61tnFhcRb/fHkpl03LxcyGrQ4RkbOhIBgCR9o6WPnqHn70YgX7G48xMz+Nf144hSvPG090lAJBREY2BcEQauvoYtXre/nhCzupONjK5JxklpQXc8U54yjISAxbXSIiA1EQhEBnl+MPm2t4cPUOtuxrAmDauBQWTs9j4bRcyoqziIuJmAO3RWSEUxCEkHOOHbUtrN5ex+q3a3l11yHaOx3JcdEsmJLDwum5LJyep96CiISVgmAYtR7vYO3OelZvr2X19jr2Hj4KwNS8lEAolBVnEh8THeZKRSSSKAjCxDnHzjq/t7C9jld3HaKts4ukuGgWlHb3FnIpzEwKd6kiMsYNFARaaS2EzIwpealMyUvlk5dMpvV4B6/srGf1215v4c9vHQBgSl4KC6d5vYX5JeotiMjwUo8gTLzeQiurt9fywtt1/K0iuLeQzWX+TueJWeotiMjZU49gBPJ6CylMyUvhk5dM5kib11t4fnt3b6EWgMLMRN49JYcFU3JYUJpNTkp8mCsXkbFGPYIRqLu38PKOg7y84yCvVNTTfKwDgBnjU1lQmkP5lGwumpxNis6jICKDoJ3Fo1xnl2Pz3kZe2nGQtTsPsr6ygeMdXURHGRdMzKC8NJsFU3KYU5Sh/Qsi0icFwRhzrL2TDbsbeHnnQV7eUc+m6sN0OUiIjWJ+cRblU3IoL83h3Pw0LX8hIoCCYMxrPNrO3yrqWbuznpd3HOSd2hYA0hNjWeD3FspLsynJSdZCeSIRSjuLx7j0xFj+fuZ4/n7meABqm44FQuHlHQd5ZnMNABPSE1hQ6u10vrg0m3wd7SwiqEcw5jnnqKw/wsv+/oW1O+s5fKQdgOLsJC4uzeZdk71gyEvV6TlFxioNDUlAV5djW00za3ce5K8V9fyt4hDNx70ZSVPyUrjYD4V3Tc4mKzkuzNWKyFBREEi/OrscW/Y1snZnPa/srGdd5SGOtHUC3lTVi0uzuXiyN1U1PTE2zNWKyJlSEMigtXd2sam6kVd2escvdE9VNYPz8tMDwTC/JEvHMIiMImELAjO7EvgBEA085Jz77gmPFwGPAhn+c+52zj090HsqCIbX8Y5ONlYd9noMFfVsrDpMW6d3DMOswvTAUFLZpCwS43QMg8hIFZYgMLNo4G3g74BqYB2w2Dm3Neg5y4HXnXPLzOxc4GnnXPFA76sgCK+jbZ1sqGpg7c6DvLKznk3VjXR0OWKjjfMK0plfnEXZpEzKirO0j0FkBAnX9NELgR3OuQq/iJXAImBr0HMckObfTgf2hbAeGQKJcdHeAWtTcgDv/AvrKg/x14pDrK88xIqXK1m+pgKA0txkLxiKs5hfnElRVpKOYxAZgUIZBAXAnqD71cBFJzznXuCPZvY5IBl4b19vZGa3ArcCFBUVDXmhcuaS42O803NOzwO8o57f3NvIuspDrK9s4Ok397NynfdrkJsaz/ziTMomZTG/OItzJqQSE63TeYqEW7j39i0GVjjn/sPMLgZ+YmbnOee6gp/knFsOLAdvaCgMdcogJcRGM7/Ya+jBm676Tm2LHwyHWFfZwNNvege4JcVFM7cok7LiTOYXZ3HBxAyStQNaZNiF8q9uLzAx6H6hvy3YPwFXAjjnXjGzBCAHqA1hXTKMoqKM6eNTmT4+lf/zrkkA7Dt8lPW7GwLB8IPn3sE5iI4yZuan+T2GTOYVZ+ogN5FhEMqdxTF4O4uvwAuAdcBHnXNbgp7zDPAL59wKMzsHeA4ocAMUpZ3FY0/TsXZerzrM+spDvLrrEBv3HOZ4h9cpLMpKYm5RBnMnZTK3KJMZ4zWcJHImwrKz2DnXYWafBZ7Fmxr6Y+fcFjP7JrDeOfck8C/Aj8zsTrwdx0sGCgEZm9ISYrlsWi6XTcsFoK2jiy37vP0Mr+1u4OWd9aza6M0jSIyNZlZheiAY5hZlkK2T9YicFR1QJiOec47qhqNsqGrg9arDbKhqYOu+Jjq6vN/dSdlJXihM8oJh+jj1GkROpNVHZVQzMyZmJTExK4lFFxQA3vEMb+5tZENVAxt2N/DiOwf57eveLqikuGhmF2Ywd1IGc4symVOUqWMaRAagIJBRKTEumgtLsriwxJudFNxr2LC7gQ1Vh/mfFyoCvYaSnGTmFGX4w0mZTB+fqpP2iPgUBDIm9Ndr2FR9mA3+cNKat+v4zQav15AYG83M/DRmFWYwqzCdWYXpFGcnE6VwkAikfQQSMZxz7Dnk9RreqD7Mm9WNbN7XyLF2b4ZSanwM5xWkM2tiOrMKvIAozEzU0dAyJoz5fQTt7e1UV1dz7NixcJcip5CQkEBhYSGxscO/pLWZUZSdRFF2Eh+c4/UaOjq72FHXwqY9jWza64XDIy9V0tbphUNWchznF6T7vQYvHMal6dgGGVvGRI9g165dpKamkp2drW9vI5hzjvr6epqbmykpKQl3Of063tHJ2zUtgV7DG9WHeae2hU5/f8O4tHjOL8hgdmE65/sBoZ3RMtKN+R7BsWPHKC4uVgiMcGZGdnY2dXV14S5lQPEx0ZzvN/LdjrZ1snV/I5uqGwPh8Ny2A3R/jyrMTGRWYTrnFaRzXr53rXCQ0WJMBAGgEBglRuv/U2JcNPMmZTFvUlZgW/OxdjbvbeLNvYd5ww+I7nWUAAoyEpmZn+aFQ0Ea5+Wnk6dhJRmBxkwQiAy31IRY74xtpdmBbY1H2tmyv5Ete5vYvK+RN/c28qe3enoOuanxnBcIB++Sn54wagNSxgYFwRCor6/niiuuAKCmpobo6Ghyc73lEl599VXi4vofIli/fj2PPfYY999//4A/Y8GCBaxdu/asa129ejVLly7ld7/73Vm/l5wsPSmWBaU5LCjNCWxrOd7BW/ub2Ly3kc17m9iyr5E17xwM7HPITIrlvIJ0Zub39ByKspI0lVWGjYJgCGRnZ7Nx40YA7r33XlJSUvjCF74QeLyjo4OYmL7/qcvKyigr63P/TS9DEQISHinxMb2W5gbvvA3bapr9cPCmsT78UgXtnV44pMbHcG5+GucXpDOzII0Z49MozU0hLkZLZ8jQG3NB8I2ntrB1X9OQvue5+Wl8/R9mntZrlixZQkJCAq+//jrl5eXccMMN3H777Rw7dozExEQeeeQRpk+f3usb+r333ktVVRUVFRVUVVVxxx138PnPfx6AlJQUWlpaWL16Nffeey85OTls3ryZefPm8dOf/hQz4+mnn+auu+4iOTmZ8vJyKioqBvzmf+jQIW6++WYqKipISkpi+fLlzJo1ixdeeIHbb78d8Mb016xZQ0tLC9dffz1NTU10dHSwbNkyLrnkkjP/R41wCbHRXDAxgwsmZgS2tXV08faBZrbs83oOm/c18pO/7g6sxBoTZUzJS2HG+FSmj09jxoRUzhmfxri0eA0tyVkZc0EwklRXV7N27Vqio6NpamrixRdfJCYmhj//+c98+ctf5oknnjjpNdu2beP555+nubmZ6dOnc9ttt5005/71119ny5Yt5OfnU15ezssvv0xZWRmf+tSnWLNmDSUlJSxevPiU9X39619nzpw5rFq1ir/85S/ceOONbNy4kaVLl/LAAw9QXl5OS0sLCQkJLF++nPe973185StfobOzkyNHjgzZv5N44mKiAvsNrp/vbevo7KLiYCvbaprZtr+J7TXNrKtsCKzGCpCeGMuM8amcMyHNDwnvkhSnP28ZnDH3m3K639xD6cMf/jDR0dEANDY2ctNNN/HOO+9gZrS3t/f5mquuuor4+Hji4+PJy8vjwIEDFBYW9nrOhRdeGNh2wQUXUFlZSUpKCpMnTw7Mz1+8eDHLly8fsL6XXnopEEbvec97qK+vp6mpifLycu666y4+9rGPce2111JYWMj8+fO5+eabaW9v54Mf/CAXXHDBWf3byODEREcxbVwq08alcs3s/MD2xqPtbK9pZltNUyAkfrV+D61tnQCYwaSsJGaMT2P6+FTOmZDKjPFp2vcgfRpzQTCSJCcnB25/9atf5fLLL+e3v/0tlZWVLFy4sM/XxMf3rK0fHR1NR0fHGT3nbNx9991cddVVPP3005SXl/Pss89y6aWXsmbNGn7/+9+zZMkS7rrrLm688cYh/bkyeOmJsb0W3QPvtKDVDUd7wqGmiW37m3l2a01g1lJibDTTxqdyTlDPYfq4VJ3TIcIpCIZJY2MjBQXesgYrVqwY8vefPn06FRUVVFZWUlxczC9+8YtTvuaSSy7h8ccf56tf/SqrV68mJyeHtLQ0du7cyfnnn8/555/PunXr2LZtG4mJiRQWFnLLLbdw/PhxNmzYoCAYYaKiepbQ+PuZ4wPbj7Z18k5tM9v2N/NWjTe89OyWGlau2xN4Tk5KPNPHpzB9XJp3PT6NaeNSNLwUIfS/PEy++MUvctNNN/Htb3+bq666asjfPzExkQcffJArr7yS5ORk5s+ff8rX3Hvvvdx8883MmjWLpKQkHn30UQDuu+8+nn/+eaKiopg5cybvf//7WblyJd///veJjY0lJSWFxx57bMg/g4RGYly0v05Sz45p5xx1LcfZXtPccznQzM9e3R1YhA+8U4V29xq6exAlOcnE6sQ/Y8qYWGvorbfe4pxzzglTRSNHS0sLKSkpOOf4zGc+w9SpU7nzzjvDXdZJ9P81cnV1OaoOHWH7gZ5w2F7TzK6DrYHjHmKjjdLcFKaP9/ZdzPCvtVLryDbm1xoSz49+9CMeffRR2tramDNnDp/61KfCXZKMMlFRRnFOMsU5ybwvaHjpeEcnO2tbeftAM9tqmtle08T6ygb+N2j2Ukp8DFPHpTAtL5XSvGSm5KUwJTeVgsxEnQRohFOPQIad/r/GjqZj7bzjh8PbNd71jtoW6lvbAs+Jj4miJMcPhrwUSnO965KcZBJio8NYfWRRj0BEQiItIfakxfgAGlrb2FnXwo7alsD1G9WH+f2b+wMzmMxgYmZSUED09CLSk4b/fBWRTEEgIkMuMzmOsuQsyop7B8Sx9k4q6lrZUdfCztqWwPVLOw7S1tGzkzonJS7Qc+i+npybTH56oo6DCAEFgYgMm4TYaM7NT+Pc/LRe2zu7HNUNR9hR27sX8dQb+2g61nOcTPcw0+TcZCbneOHg3U8hPVG9iDOlIBCRsIuOMiZlJzMpO5krzhkX2O6c42BLGztqW6g42MKuulYqDraydV8Tz245EJjJBF4voiTn5IAoykrSYn2noCAYApdffjl3330373vf+wLb7rvvPrZv3+OrSNgAAAzMSURBVM6yZcv6fM3ChQtZunQpZWVlfOADH+BnP/sZGRkZvZ7T10qmJ1q1ahXTpk3j3HPPBeBrX/sal156Ke9973vP6jNpuWoZCcyM3NR4clPje533AbxF+qoOHaGiroVdB1upqGul4mALz207wC/W9+ysjo4yirKS/JDwwqEkJ5nS3GRyU7VgHygIhsTixYtZuXJlryBYuXIl3/ve9wb1+qeffvqMf/aqVau4+uqrA0HwzW9+84zfS2Q0iYuJCuxoPlHjkXavBxEUEBV1rby842BgNVfwprxOyk6iOCeZkmxv2mxJThKTspPJTo6LmJAYe0HwzN1Q8+bQvuf48+H93+334euuu4577rmHtrY24uLiqKysZN++fVxyySXcdtttrFu3jqNHj3LdddfxjW9846TXFxcXs379enJycvjOd77Do48+Sl5eHhMnTmTevHmAd4zA8uXLaWtrY8qUKfzkJz9h48aNPPnkk7zwwgt8+9vf5oknnuBb3/oWV199Nddddx3PPfccX/jCF+jo6GD+/PksW7aM+Ph4iouLuemmm3jqqadob2/nV7/6FTNmzOj382m5ahlt0pNimVOUyZyizF7bu7oc+xqPBgJi10HvsnlvI3/YXNNrqCk1PiZwTEVJthcOXlAkk5kUO6ZCYuwFQRhkZWVx4YUX8swzz7Bo0SJWrlzJRz7yEcyM73znO2RlZdHZ2ckVV1zBpk2bmDVrVp/v89prr7Fy5Uo2btxIR0cHc+fODQTBtddeyy233ALAPffcw8MPP8znPvc5rrnmmkDDH+zYsWMsWbKE5557jmnTpnHjjTeybNky7rjjDgBycnLYsGEDDz74IEuXLuWhhx7q9/NpuWoZK6KijMLMJAozk7hkam6vx9o7u6huOEqlHw6V9d71G3sO8/tN+wjKCNISYijJSQ4KhySKs72QyEjq/4yEI9XYC4IBvrmHUvfwUHcQPPzwwwD88pe/ZPny5XR0dLB//362bt3abxC8+OKLfOhDHyIpKQmAa665JvDY5s2bueeeezh8+DAtLS29hqH6sn37dkpKSpg2bRoAN910Ew888EAgCK699loA5s2bx29+85sB30vLVUskiI32ZiSV5CRz+QmPtXV0safhSCAkdtcfobK+lQ1VDTy1aR/Bx+VmJMV6O76zkijOTqIoO5lJ2UlMyk4iN2Vk7pMIaRCY2ZXAD4Bo4CHn3EmttJl9BLgXcMAbzrmPhrKmUFm0aBF33nknGzZs4MiRI8ybN49du3axdOlS1q1bR2ZmJkuWLOHYsWNn9P5Llixh1apVzJ49mxUrVrB69eqzqrd7KeuzWcZay1VLpIiLiaI01zum4UTHOzrZc+gIlQePBHoRu+uP8PqeBn53Qk8iKS6aoqwkPxj8gMjyrvMzwrcUR8iCwMyigQeAvwOqgXVm9qRzbmvQc6YCXwLKnXMNZpYXqnpCLSUlhcsvv5ybb745cHawpqYmkpOTSU9P58CBAzzzzDP9nocA4NJLL2XJkiV86UtfoqOjg6eeeiqwXlBzczMTJkygvb2dxx9/PLCkdWpqKs3NzSe91/Tp06msrGTHjh2BfQqXXXbZGX02LVct0r/4mGim5KUyJS/1pMfaOrrYe/gou+u9cPAureysa+X57XW9DqKLjfaGrbxwCAqK7GQmZiUSHxO65ThC2SO4ENjhnKsAMLOVwCJga9BzbgEecM41ADjnakNYT8gtXryYD33oQ6xcuRKA2bNnM2fOHGbMmMHEiRMpLy8f8PVz587l+uuvZ/bs2eTl5fVaSvpb3/oWF110Ebm5uVx00UWBxv+GG27glltu4f777+fXv/514PkJCQk88sgjfPjDHw7sLP70pz99Rp9Ly1WLnJm4mJ7hphN1dTlqmo4FwmH3oSNU+UNOr1U20Hy8p6duBhPSEvhEeQm3XDp5yOsM2aJzZnYdcKVz7pP+/Y8DFznnPhv0nFXA20A53vDRvc65P/TxXrcCtwIUFRXN2717d6/HtYjZ6KL/L5GBOec41NrWKxyq6o9w2fRcFl1QcEbvOZIXnYsBpgILgUJgjZmd75w7HPwk59xyYDl4q48Od5EiIsPJzMhOiSc7JZ65J0yBDYVQHne9F5gYdL/Q3xasGnjSOdfunNuF1zuYGsKaRETkBKEMgnXAVDMrMbM44AbgyROeswqvN4CZ5QDTgIoz+WGj7bwKkUr/TyIjT8iCwDnXAXwWeBZ4C/ilc26LmX3TzLonyD8L1JvZVuB54F+dc/Wn+7MSEhKor69XIzPCOeeor68nISEh3KWISJAxcYay9vZ2qqurz3iOvgyfhIQECgsLiY3VksEiw2kk7yweErGxsZSUlIS7DBGRUUmLdIuIRDgFgYhIhFMQiIhEuFG3s9jM6oDdp3xi33KAg0NYTqiNpnpHU60wuuodTbXC6Kp3NNUKZ1fvJOdcbl8PjLogOBtmtr6/veYj0WiqdzTVCqOr3tFUK4yuekdTrRC6ejU0JCIS4RQEIiIRLtKCYHm4CzhNo6ne0VQrjK56R1OtMLrqHU21Qojqjah9BCIicrJI6xGIiMgJFAQiIhEuYoLAzK40s+1mtsPM7g53Pf0xs4lm9ryZbTWzLWZ2e7hrGgwzizaz183sd+GuZSBmlmFmvzazbWb2lpldHO6aBmJmd/q/B5vN7OdmNqKWbjWzH5tZrZltDtqWZWZ/MrN3/OvQn1llEPqp9fv+78ImM/utmWWEs8ZgfdUb9Ni/mJnzl+8/axERBGYWDTwAvB84F1hsZueGt6p+dQD/4pw7F3gX8JkRXGuw2/GWGx/pfgD8wTk3A5jNCK7ZzAqAzwNlzrnz8E7nekN4qzrJCuDKE7bdDTznnJsKPOffHwlWcHKtfwLOc87Nwjsx1peGu6gBrODkejGzicDfA1VD9YMiIgiAC4EdzrkK51wbsBJYFOaa+uSc2++c2+DfbsZrqM7sJKXDxMwKgauAh8Jdy0DMLB24FHgYwDnXduJpUUegGCDRzGKAJGBfmOvpxTm3Bjh0wuZFwKP+7UeBDw5rUf3oq1bn3B/9c6cA/BXvTIojQj//tgD/BXwRGLKZPpESBAXAnqD71YzwxhXAzIqBOcDfwlvJKd2H94vZFe5CTqEEqAMe8YexHjKz5HAX1R/n3F5gKd43v/1Ao3Puj+GtalDGOef2+7drgHHhLOY03Aw8E+4iBmJmi4C9zrk3hvJ9IyUIRh0zSwGeAO5wzjWFu57+mNnVQK1z7rVw1zIIMcBcYJlzbg7QysgZtjiJP7a+CC/A8oFkM/s/4a3q9DhvfvqIn6NuZl/BG5Z9PNy19MfMkoAvA18b6veOlCDYC0wMul/obxuRzCwWLwQed879Jtz1nEI5cI2ZVeINub3HzH4a3pL6VQ1UO+e6e1i/xguGkeq9wC7nXJ1zrh34DbAgzDUNxgEzmwDgX9eGuZ4BmdkS4GrgY25kH1hVivel4A3/760Q2GBm48/2jSMlCNYBU82sxMzi8Ha4PRnmmvpkZoY3hv2Wc+4/w13PqTjnvuScK3TOFeP9u/7FOTciv7U652qAPWY23d90BbA1jCWdShXwLjNL8n8vrmAE79wO8iRwk3/7JuB/w1jLgMzsSrxhzWucc0fCXc9AnHNvOufynHPF/t9bNTDX/70+KxERBP7OoM8Cz+L9If3SObclvFX1qxz4ON43643+5QPhLmoM+RzwuJltAi4A/j3M9fTL77n8GtgAvIn39zqilkQws58DrwDTzazazP4J+C7wd2b2Dl6v5rvhrLFbP7X+N5AK/Mn/W/thWIsM0k+9oflZI7snJCIioRYRPQIREemfgkBEJMIpCEREIpyCQEQkwikIREQinIJA5ARm1hk0dXfjUK5Wa2bFfa0mKRJOMeEuQGQEOuqcuyDcRYgMF/UIRAbJzCrN7Htm9qaZvWpmU/ztxWb2F39N++fMrMjfPs5f4/4N/9K9PES0mf3IP8/AH80sMWwfSgQFgUhfEk8YGro+6LFG59z5eEek3udv+3/Ao/6a9o8D9/vb7wdecM7NxlvTqPto9qnAA865mcBh4B9D/HlEBqQji0VOYGYtzrmUPrZXAu9xzlX4CwPWOOeyzewgMME51+5v3++cyzGzOqDQOXc86D2KgT/5J23BzP4NiHXOfTv0n0ykb+oRiJwe18/t03E86HYn2lcnYaYgEDk91wddv+LfXkvPKSQ/Brzo334OuA0C53ROH64iRU6HvomInCzRzDYG3f+Dc657Cmmmv3LpcWCxv+1zeGc9+1e8M6B9wt9+O7DcXzWyEy8U9iMywmgfgcgg+fsIypxzB8Ndi8hQ0tCQiEiEU49ARCTCqUcgIhLhFAQiIhFOQSAiEuEUBCIiEU5BICIS4f4/9DtYjjgKF0gAAAAASUVORK5CYII=\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","execution_count":27,"metadata":{"id":"SXpn2XqVuKAj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651425828875,"user_tz":240,"elapsed":348,"user":{"displayName":"Pablo Amezquita","userId":"04689184241608460117"}},"outputId":"39698c3a-b187-4438-a2d1-a52ce74ec113"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_3 (InputLayer)         [(None, None)]            0         \n","_________________________________________________________________\n","embedding_2 (Embedding)      (None, None, 300)         4650900   \n","_________________________________________________________________\n","lstm (LSTM)                  [(None, None, 300), (None 721200    \n","=================================================================\n","Total params: 5,372,100\n","Trainable params: 5,372,100\n","Non-trainable params: 0\n","_________________________________________________________________\n","Model: \"model_3\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_4 (InputLayer)            [(None, None)]       0                                            \n","__________________________________________________________________________________________________\n","embedding_3 (Embedding)         (None, None, 300)    5810400     input_4[0][0]                    \n","__________________________________________________________________________________________________\n","input_5 (InputLayer)            [(None, 300)]        0                                            \n","__________________________________________________________________________________________________\n","input_6 (InputLayer)            [(None, 300)]        0                                            \n","__________________________________________________________________________________________________\n","lstm_1 (LSTM)                   [(None, None, 300),  721200      embedding_3[0][0]                \n","                                                                 input_5[0][0]                    \n","                                                                 input_6[0][0]                    \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, None, 19368)  5829768     lstm_1[1][0]                     \n","==================================================================================================\n","Total params: 12,361,368\n","Trainable params: 12,361,368\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}],"source":["#lstm encoder and decoder models\n","lstm_encoder_model = keras.models.Model(lstm_inputs, lstm_encoder_states) #define the encoder with the trainined weights\n","\n","lstm_encoder_model.summary()\n","#get the decoder model\n","lstm_decoder_state_h = layers.Input(shape=(hidden_size,))#initialize the inputs for the hidden state from the encoder\n","lstm_decoder_state_c = layers.Input(shape=(hidden_size,))#initialize the inputs for the cell state from the encoder\n","lstm_decoder_states_inputs = [lstm_decoder_state_h, lstm_decoder_state_c]#context vector from the encoder as the input\n","decoder_outputs_lstm, state_h, state_c = lstm_decoder(lstm_decoder_embedding_with_Inputs, initial_state = lstm_decoder_states_inputs)#apply the trainined decoder to the embedding layer\n","decoder_states_lstm = [state_h, state_c]#output of the decoder as a vector\n","decoder_outputs_lstm = lstm_dense(decoder_outputs_lstm)#apply the dense layer to the outputs of the decoder\n","lstm_decoder_model = keras.models.Model([lstm_decoder_input]+lstm_decoder_states_inputs, [decoder_outputs_lstm]+decoder_states_lstm)#set the decoder model with inputs as the dcoder inputs plus the encoder context vector. and the outputs as the decoder output plus the context vector\n","\n","lstm_decoder_model.summary()"]},{"cell_type":"code","source":["#simpleRNN encoder and decoder models\n","simpleRNN_encoder_model = keras.models.Model(simple_RNN_inputs, simple_RNN_encoder_states)#define the encoder with the trainined weights\n","\n","simpleRNN_encoder_model.summary()\n","#get the encoder model\n","simpleRNN_decoder_state = layers.Input(shape=(hidden_size,))#initialize the input for the context vector from the encoder\n","simpleRNN_decoder_states_inputs = [simpleRNN_decoder_state]#set context vector as a list\n","decoder_outputs_simpleRNN, return_state = simpleRNN_decoder(simpleRNN_decoder_embedding_with_Inputs, initial_state = simpleRNN_decoder_states_inputs)#apply the trained simpleRNN decoder to the embedding with the initial state as the encoder context vector\n","decoder_states_simpleRNN = [return_state]#save the output as a list\n","decoder_outputs_simpleRNN = simpleRNN_dense(decoder_outputs_simpleRNN)#apply the dense layer\n","simpleRNN_decoder_model = keras.models.Model([simpleRNN_decoder_input]+simpleRNN_decoder_states_inputs, [decoder_outputs_simpleRNN]+decoder_states_simpleRNN)#set the decoder model with inputs as the dcoder inputs plus the encoder context vector. and the outputs as the decoder output plus the context vector\n","\n","simpleRNN_decoder_model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NDoQcFM0p4BF","executionInfo":{"status":"ok","timestamp":1650426357528,"user_tz":240,"elapsed":30,"user":{"displayName":"Pablo Amezquita","userId":"04689184241608460117"}},"outputId":"f2a06492-9ef1-47cf-e654-f640dd80ec90"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_13\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_1 (InputLayer)         [(None, None)]            0         \n","_________________________________________________________________\n","embedding (Embedding)        (None, None, 300)         4678800   \n","_________________________________________________________________\n","simple_rnn (SimpleRNN)       [(None, 300), (None, 300) 180300    \n","=================================================================\n","Total params: 4,859,100\n","Trainable params: 4,859,100\n","Non-trainable params: 0\n","_________________________________________________________________\n","Model: \"model_14\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_13 (InputLayer)           [(None, None)]       0                                            \n","__________________________________________________________________________________________________\n","embedding_8 (Embedding)         (None, None, 300)    5886000     input_13[0][0]                   \n","__________________________________________________________________________________________________\n","input_16 (InputLayer)           [(None, 300)]        0                                            \n","__________________________________________________________________________________________________\n","simple_rnn_2 (SimpleRNN)        [(None, None, 300),  180300      embedding_8[0][0]                \n","                                                                 input_16[0][0]                   \n","__________________________________________________________________________________________________\n","dense_4 (Dense)                 (None, None, 19620)  5905620     simple_rnn_2[1][0]               \n","==================================================================================================\n","Total params: 11,971,920\n","Trainable params: 11,971,920\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["#GRU inference\n","gru_encoder_model = keras.models.Model(gru_inputs, gru_encoder_states, name=\"GRU_Encoder\")#define the encoder with the trainined weights\n","\n","gru_encoder_model.summary()\n","#get the decoder model\n","gru_decoder_state = layers.Input(shape=(hidden_size,))#initialize the input for the context vector from the encoder\n","gru_decoder_states_inputs = [gru_decoder_state]#set context vector as a list\n","decoder_outputs_gru, return_state = gru_decoder(gru_decoder_embedding_with_Inputs, initial_state = gru_decoder_states_inputs)#apply the trained GRU decoder to the embedding with the initial state as the encoder context vector\n","decoder_states_gru = [return_state]#save the output as a list\n","decoder_outputs_gru = gru_dense(decoder_outputs_gru)#apply the dense layer\n","gru_decoder_model = keras.models.Model([gru_decoder_input]+gru_decoder_states_inputs, [decoder_outputs_gru]+decoder_states_gru, name=\"Gru_Decoder\")#set the decoder model with inputs as the dcoder inputs plus the encoder context vector. and the outputs as the decoder output plus the context vector\n","\n","gru_decoder_model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vW39afU2y8Zq","executionInfo":{"status":"ok","timestamp":1650426357529,"user_tz":240,"elapsed":24,"user":{"displayName":"Pablo Amezquita","userId":"04689184241608460117"}},"outputId":"06de3eed-3fc0-485a-98f3-6d58f9a7e485"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"GRU_Encoder\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_3 (InputLayer)         [(None, None)]            0         \n","_________________________________________________________________\n","embedding_2 (Embedding)      (None, None, 300)         4678800   \n","_________________________________________________________________\n","gru (GRU)                    [(None, 300), (None, 300) 541800    \n","=================================================================\n","Total params: 5,220,600\n","Trainable params: 5,220,600\n","Non-trainable params: 0\n","_________________________________________________________________\n","Model: \"Gru_Decoder\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_6 (InputLayer)            [(None, None)]       0                                            \n","__________________________________________________________________________________________________\n","embedding_5 (Embedding)         (None, None, 300)    5886000     input_6[0][0]                    \n","__________________________________________________________________________________________________\n","input_17 (InputLayer)           [(None, 300)]        0                                            \n","__________________________________________________________________________________________________\n","gru_1 (GRU)                     [(None, None, 300),  541800      embedding_5[0][0]                \n","                                                                 input_17[0][0]                   \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, None, 19620)  5905620     gru_1[2][0]                      \n","==================================================================================================\n","Total params: 12,333,420\n","Trainable params: 12,333,420\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","execution_count":28,"metadata":{"id":"zHkx9y7CO3F4","executionInfo":{"status":"ok","timestamp":1651425843712,"user_tz":240,"elapsed":358,"user":{"displayName":"Pablo Amezquita","userId":"04689184241608460117"}}},"outputs":[],"source":["def decode(encoder_model, decoder_model, input_sequence, maxlen, lstm):\n","    # input_sequence = np.reshape(input_sequence, (-1, 1, maxlen))\n","    states_value = encoder_model.predict(input_sequence)#get the context vector from the encoder\n","    end = False#set the end condition as false\n","    greedy_sentence = np.array([])#this is the sentence so fat\n","    decoder_input = np.array([target_token2idx[\"<start>\"]])#start the translation from the <start> tag\n","    # decoder_model.summary()\n","    # print(np.shape(states_value))\n","    # print([decoder_input]+states_value)\n","\n","    #while we have not reached an end tag or max length\n","    while not end:\n","        if lstm:\n","          predictions, h, c = decoder_model.predict([decoder_input] + states_value)#if its an lstm predict the probabilities of words and save the ouputs\n","        else:\n","          predictions, return_state = decoder_model.predict([decoder_input]+[states_value])#if its not an lstm predict the probabilities of words and save the output\n","            \n","        greedy = np.argmax(predictions[0, -1, :])#take the word with the highest probability (GREEDY)\n","        predicted_word = target_vocab[greedy]#get the word in the target language\n","        \n","        greedy_sentence = np.append(greedy_sentence, predicted_word)#add the word to the sentence so far\n","        end=predicted_word==\"<end>\" or len(greedy_sentence)>=maxlen#check if we should end\n","        decoder_input = np.array([greedy])#the predicted word is the next decoder input\n","        states_value = [h,c] if lstm else [return_state]#the context vector of the predicted word\n","    # print(greedy_sentence)    \n","    return greedy_sentence "]},{"cell_type":"code","source":["# def beam_decoder(encoder_model, decoder_model, input_sequence, timesteps, num_hypotheses, lstm):\n","#     states_value = encoder_model.predict(input_sequence)\n","#     beam_all_values = np.array([])\n","#     decoder_inputs = np.array([[target_token2idx[\"<start>\"]]])\n","#     i = 0\n","#     while i < timesteps and len(beam_all_values) < num_hypotheses:\n","#         for d_input in decoder_inputs:\n","#             if lstm:\n","#                 predictions, h, c = decoder_model.predict([d_input]+states_value)\n","#             else:\n","#                 predictions, return_state = decoder_model.predict([d_input]+[states_value])\n","\n","            "],"metadata":{"id":"FyRxVyTxeEOH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["decode(gru_encoder_model, gru_decoder_model, test_encoder_input[3:4], max_source_len_test, lstm=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3XvOcYC3s2nl","executionInfo":{"status":"ok","timestamp":1650426357530,"user_tz":240,"elapsed":15,"user":{"displayName":"Pablo Amezquita","userId":"04689184241608460117"}},"outputId":"c0342bc9-aa8d-467c-89b7-9c55af21b345"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['je', 'suis', 'favorable', 'à', 'la', 'nécessité', 'de',\n","       'procéder', 'à', 'la', 'nécessité', 'de', 'la', 'nécessité', 'de',\n","       'réaliser', 'les', 'principes', 'de', 'la', 'sûreté', 'et', 'de',\n","       'la', 'sécurité', '.', '<end>'], dtype='<U32')"]},"metadata":{},"execution_count":88}]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1wRYdUhVO3F4","executionInfo":{"status":"ok","timestamp":1651425852058,"user_tz":240,"elapsed":3760,"user":{"displayName":"Pablo Amezquita","userId":"04689184241608460117"}},"outputId":"e7530896-0560-4f72-8588-e76421dd4c49"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['je', 'voudrais', 'dire', 'que', 'la', 'commission', 'a', 'été',\n","       'adoptée', 'par', 'le', 'parlement', ',', 'qui', 'a', 'été',\n","       'adoptée', 'par', 'le', 'parlement', ',', 'qui', 'a', 'été', 'dit',\n","       ',', 'je', 'voudrais', 'dire', 'que', 'la', 'commission', 'a',\n","       'été', 'adoptée', 'par', 'le', 'parlement', ',', 'qui', 'a', 'été',\n","       'dit', ',', 'à', 'la', 'commission', ',', 'et', 'je', 'suis',\n","       'heureux', 'que', 'nous', 'avons', 'besoin', 'd', \"'\", 'une',\n","       'politique', 'de', 'la', 'commission', '.', '<end>'], dtype='<U32')"]},"metadata":{},"execution_count":29}],"source":["decode(lstm_encoder_model, lstm_decoder_model, test_encoder_input[3:4], max_source_len_test, lstm=True)"]},{"cell_type":"code","source":["input = np.array([test_encoder_input[3]])\n","decode(simpleRNN_encoder_model, simpleRNN_decoder_model, input, max_source_len_test, lstm=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NAMFrdMYHuho","executionInfo":{"status":"ok","timestamp":1650426361375,"user_tz":240,"elapsed":2056,"user":{"displayName":"Pablo Amezquita","userId":"04689184241608460117"}},"outputId":"08abd7e0-2787-440b-a068-bb7dacc61887"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['je', 'voudrais', 'souligner', 'que', 'la', 'commission', 'a',\n","       'déjà', 'été', 'dit', ',', 'mais', 'je', 'ne', 'suis', 'pas',\n","       'eurofédéraliste', '-', 'et', 'je', 'suis', 'convaincu', 'que',\n","       'nous', 'avons', 'besoin', 'd', \"'\", 'une', 'politique', 'de',\n","       'voisinage', '.', '<end>'], dtype='<U32')"]},"metadata":{},"execution_count":90}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DxZ2tolXO3F4","executionInfo":{"status":"ok","timestamp":1650426361376,"user_tz":240,"elapsed":16,"user":{"displayName":"Pablo Amezquita","userId":"04689184241608460117"}},"outputId":"c69dd5fc-b943-4ecf-9b54-39ceb2beb11d"},"outputs":[{"output_type":"stream","name":"stdout","text":["['cela', 'permettre', 'à', 'chaque', 'pays', 'de', 'disposer', 'de', 'sa', 'capacité', 'de', 'recyclage', 'optimale', 'car', 'chaque', 'producteur', 'de', 'matériaux', 'aura', 'intérêt', 'à', 'recycler', '.']\n","[('i am aware of the efforts that were made in the negotiations between parliament and the council aimed at achieving agreement at the first reading .', \"j' ai conscience des efforts consentis dans les négociations entre le parlement et le conseil en vue d' obtenir un accord en première lecture .\")]\n"]}],"source":["# print([test_encoder_input[0]])\n","\n","print(valid_texts[3][1].split(' '))\n","print(test_texts[3:4])\n","# [[source_token2idx[\"hi\"], source_token2idx[\"there\"]]]"]},{"cell_type":"code","source":["def calc_bleu_score(num_samples,encoder_model, decoder_model, data_input,data_output, maxlen, lstm):\n","    score = 0\n","    for i in tqdm(range(num_samples)): #using the entire data set was supposed to take 40 minutes, so i used a sample size to make the run time more reasonable, 100 samples was about 2 minutes\n","        predicted_translation = decode(encoder_model, decoder_model, np.array([data_input[i]]), maxlen, lstm)#predict the sentence\n","        ground_truth = data_output[i][1].split(' ')#get the fround truth as a list\n","        score += sentence_bleu([ground_truth], predicted_translation)#calculate the bleu score\n","    score /= len(data_input)#average the bleu score\n","    print(score)\n","    return score"],"metadata":{"id":"H1uczeWbkxyn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lstm_bleu = calc_bleu_score(300,lstm_encoder_model, lstm_decoder_model, val_encoder_input, valid_texts, max_target_len_val, lstm=True)#calcualte LSTM bleu for validation"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":275,"referenced_widgets":["ebe0f045034148429e0f0f2872a3fac4","14043a5696af4a38a93b53380ca2f8ea","3be6153bd8bd417cb1bdd0988680f0dd","fb58e118cf5e441e9af46318fd6732de","f9f2630ef4454612b015dc275b4065ed","86d9e4c2b4224853904cac808a23a083","ad5f23544dab4cf9b63ebc195802154c","f7c016c8bb5d488abadaf8b705c1e2ef","7c1952e067774268b7161e6a3e65b99c","2aeae9cd4d624a85b165b14d61e35311","fd82f923d7de4a68b6f0603d5d1809fc"]},"id":"CO-jx0CppU-d","executionInfo":{"status":"ok","timestamp":1650426836591,"user_tz":240,"elapsed":475228,"user":{"displayName":"Pablo Amezquita","userId":"04689184241608460117"}},"outputId":"de4894d7-25a8-4734-8241-56d0afa4801f"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/300 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ebe0f045034148429e0f0f2872a3fac4"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n","Corpus/Sentence contains 0 counts of 2-gram overlaps.\n","BLEU scores might be undesirable; use SmoothingFunction().\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n","Corpus/Sentence contains 0 counts of 3-gram overlaps.\n","BLEU scores might be undesirable; use SmoothingFunction().\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n","Corpus/Sentence contains 0 counts of 4-gram overlaps.\n","BLEU scores might be undesirable; use SmoothingFunction().\n","  warnings.warn(_msg)\n"]},{"output_type":"stream","name":"stdout","text":["0.04158467033149026\n"]}]},{"cell_type":"code","source":["gru_bleu = calc_bleu_score(300,gru_encoder_model, gru_decoder_model, val_encoder_input, valid_texts, max_target_len_val, lstm=False)#calculate GRU bleu for validation set"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":275,"referenced_widgets":["dcca7800c9bb448d84c13e8bbab4e70e","08274abe4caa4614bcba0ebd1726c550","e645281fd7d54ea692859012ae10f347","ff424a8910b1480590d67234a19fa932","4eb503b560134436a5fe21a833a05ed4","ba11e18a14364f71b5a9cb74475724dd","1d0bdcf5c13b4015a621e3e62791cc2d","fa373e69f48c46ea8f1e93766753fb1e","5d6aa76eeeda465c82b08f3113e7b844","2a2e3411a2d44c438dd5227fb1a83f53","85eca978857544009e2449190ccadc67"]},"id":"pxwcWCJCzM0z","executionInfo":{"status":"ok","timestamp":1650427335743,"user_tz":240,"elapsed":499172,"user":{"displayName":"Pablo Amezquita","userId":"04689184241608460117"}},"outputId":"7bc8e5dd-85c5-4d81-f1cd-5fc8a9ac707a"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/300 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dcca7800c9bb448d84c13e8bbab4e70e"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n","Corpus/Sentence contains 0 counts of 3-gram overlaps.\n","BLEU scores might be undesirable; use SmoothingFunction().\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n","Corpus/Sentence contains 0 counts of 2-gram overlaps.\n","BLEU scores might be undesirable; use SmoothingFunction().\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n","Corpus/Sentence contains 0 counts of 4-gram overlaps.\n","BLEU scores might be undesirable; use SmoothingFunction().\n","  warnings.warn(_msg)\n"]},{"output_type":"stream","name":"stdout","text":["0.03323169794295218\n"]}]},{"cell_type":"code","source":["simpleRNN_bleu = calc_bleu_score(300,simpleRNN_encoder_model, simpleRNN_decoder_model, val_encoder_input, valid_texts, max_target_len_val, lstm=False)#calcualte simpleRNN bleu for validation set"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":275,"referenced_widgets":["389e115f13d846549d06d5c20ae4c272","729d92711825439098a2e3cb4259c5cf","bfe8117fe9d44ac7b01c38eb18e100f0","f765c36d8d554577b352d532ded1a471","fcb32ecccb414cdab62422484f52c336","240795d0a32b4cc8abec4c7b9af1ab7f","9b2c7456f0e74dc4a104a38604ada858","38045702e5f04369b7c3df80fd148755","5ec9656f13c04d8581179ebfc50ac5ad","139d10a8df0c45678bdcff533c0d2a4d","314b9e716c964cb2a879688c56a0c09f"]},"id":"25ykGVMGzVnZ","executionInfo":{"status":"ok","timestamp":1650427806863,"user_tz":240,"elapsed":471135,"user":{"displayName":"Pablo Amezquita","userId":"04689184241608460117"}},"outputId":"16a54e4a-2859-4c66-f757-cde92f78af9e"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/300 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"389e115f13d846549d06d5c20ae4c272"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n","Corpus/Sentence contains 0 counts of 2-gram overlaps.\n","BLEU scores might be undesirable; use SmoothingFunction().\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n","Corpus/Sentence contains 0 counts of 3-gram overlaps.\n","BLEU scores might be undesirable; use SmoothingFunction().\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n","Corpus/Sentence contains 0 counts of 4-gram overlaps.\n","BLEU scores might be undesirable; use SmoothingFunction().\n","  warnings.warn(_msg)\n"]},{"output_type":"stream","name":"stdout","text":["0.038952829570361246\n"]}]},{"cell_type":"code","source":["#get the model with the best bleu score on the validation set\n","models = [\"LSTM\", \"GRU\", \"Simple RNN\"]\n","scores = [lstm_bleu, gru_bleu, simpleRNN_bleu]\n","best_bleu = np.argmax(scores)\n","\n","print(f'Best Model: {models[best_bleu]} Score: {scores[best_bleu]}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OwD1wbmSeCu0","executionInfo":{"status":"ok","timestamp":1650427806864,"user_tz":240,"elapsed":18,"user":{"displayName":"Pablo Amezquita","userId":"04689184241608460117"}},"outputId":"56c561e9-341c-4531-f4c5-a6f84a743fca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Best Model: LSTM Score: 0.04158467033149026\n"]}]},{"cell_type":"markdown","metadata":{"id":"uxe83m14iD1p"},"source":["## 4. Evaluation (20 points)\n","1. Calculate the BLEU scores of the best seq2seq model obtained from section 2&3 on the test set.\n","2. Select 20 test examples, For each example, print the translation result of your model along with the ground truth"]},{"cell_type":"markdown","metadata":{"id":"hzjyr6m4iD1q"},"source":["### 4.1 Calculate the BLEU score on test set. (10 points)"]},{"cell_type":"code","source":["#Print the bleu score of the best model that was predicted on the test set\n","if models[best_bleu]==\"LSTM\":\n","    calc_bleu_score(100,lstm_encoder_model, lstm_decoder_model, test_encoder_input, test_texts, max_target_len_val, lstm=True)\n","elif models[best_bleu]==\"GRU\":\n","    calc_bleu_score(100,gru_encoder_model, gru_decoder_model, test_encoder_input, test_texts, max_target_len_val, lstm=False)\n","else:\n","    calc_bleu_score(100,simpleRNN_encoder_model, simpleRNN_decoder_model, test_encoder_input, test_texts, max_target_len_val, lstm=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":275,"referenced_widgets":["24b198502bd849b5b63b3e5a38b1ec3b","7b3d59daf35f4c2487d5ed7911ae33ca","e9963d4b55a0463eb466947135347b9b","2a33f1aee00943c0ab65cc2c541c977a","13319d1d0b224c6a834cdb0f9cf4e8fa","35b181d5d9d349debd06272f858bb9e3","a9ff4a4a2fc84e3fac875ca11f445e2f","e9ae467506c9412c8c82def6e27bbcc2","d6bea26ab15844dcac0d7e0c822b1d4c","7073b426fabf486cb5809f9a486617a9","dcc0ac0dd31846ea88bcab2464ab5279"]},"id":"MRm23yFLfH-p","executionInfo":{"status":"ok","timestamp":1650427950524,"user_tz":240,"elapsed":143668,"user":{"displayName":"Pablo Amezquita","userId":"04689184241608460117"}},"outputId":"0db26b27-2325-4055-8699-d39abc474125"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/100 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24b198502bd849b5b63b3e5a38b1ec3b"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n","Corpus/Sentence contains 0 counts of 2-gram overlaps.\n","BLEU scores might be undesirable; use SmoothingFunction().\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n","Corpus/Sentence contains 0 counts of 3-gram overlaps.\n","BLEU scores might be undesirable; use SmoothingFunction().\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n","Corpus/Sentence contains 0 counts of 4-gram overlaps.\n","BLEU scores might be undesirable; use SmoothingFunction().\n","  warnings.warn(_msg)\n"]},{"output_type":"stream","name":"stdout","text":["0.011263490478114075\n"]}]},{"cell_type":"markdown","metadata":{"id":"O8hPGbnCuKdS"},"source":["### 4.2 Translate 20 test exmaples. (10 points)"]},{"cell_type":"code","source":["#print 20 translations with the best model\n","\n","if models[best_bleu]==\"LSTM\":\n","    for i in range(20):\n","        predicted_sentence = decode(lstm_encoder_model, lstm_decoder_model, test_encoder_input[i:i+1], max_source_len_test, lstm=True)\n","        predicted_sentence = ' '.join(predicted_sentence)\n","        print(f'English: {test_texts[i][0]}\\nGround Truth French: {test_texts[i][1]}\\nPredicted Translation: {predicted_sentence}\\n')\n","elif models[best_bleu]==\"GRU\":\n","    for i in range(20):\n","        predicted_sentence = decode(gru_encoder_model, gru_decoder_model, test_encoder_input[i:i+1], max_source_len_test, lstm=False)\n","        predicted_sentence = ' '.join(predicted_sentence)\n","        print(f'English: {test_texts[i][0]}\\nGround Truth French: {test_texts[i][1]}\\nPredicted Translation: {predicted_sentence}\\n')\n","else:\n","    for i in range(20):\n","        predicted_sentence = decode(simpleRNN_encoder_model, simpleRNN_decoder_model, test_encoder_input[i:i+1], max_source_len_test, lstm=False)\n","        predicted_sentence = ' '.join(predicted_sentence)\n","        print(f'English: {test_texts[i][0]}\\nGround Truth French: {test_texts[i][1]}\\nPredicted Translation: {predicted_sentence}\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V5LeC5IqzUdc","executionInfo":{"status":"ok","timestamp":1650430321626,"user_tz":240,"elapsed":32632,"user":{"displayName":"Pablo Amezquita","userId":"04689184241608460117"}},"outputId":"fcc76dde-9d4c-4a7b-d737-2d7b9ab65502"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["English: a repressive approach should always be accompanied by a strong social commitment .\n","Ground Truth French: il faut constamment allier une approche restrictive à un engagement fort sur le plan social .\n","Predicted Translation: je voudrais également dire que la commission a été adoptée . <end>\n","\n","English: ( it ) mr president , ladies and gentlemen , i would like to thank mrs lynne for her work .\n","Ground Truth French: ( it ) monsieur le président , mesdames et messieurs , j' aimerais remercier mme lynne pour son travail .\n","Predicted Translation: monsieur le président , je voudrais remercier le rapporteur , monsieur le commissaire , je voudrais remercier le rapporteur . <end>\n","\n","English: we have seen controversial presidential elections of this kind outside europe in mexico and kenya , and within europe in belarus , russia , georgia and armenia .\n","Ground Truth French: nous avons vu des élections présidentielles controversées de ce genre en dehors de l' europe , au mexique et au kenya , et en europe , en biélorussie , en russie , en géorgie et en arménie .\n","Predicted Translation: je voudrais également dire que la commission a été adoptée par le conseil , qui a été dit , je ne pas pas de faire . <end>\n","\n","English: i am aware of the efforts that were made in the negotiations between parliament and the council aimed at achieving agreement at the first reading .\n","Ground Truth French: j' ai conscience des efforts consentis dans les négociations entre le parlement et le conseil en vue d' obtenir un accord en première lecture .\n","Predicted Translation: je voudrais également dire que la commission a été adoptée par le conseil , qui a été dit , je ne pas pas de faire . <end>\n","\n","English: at the same time , i shudder at the thought that we are surrounded by a network of informants and i wonder if the purpose of such clarity was perhaps to remind us of this and warn us that our slightest misdemeanours are under constant surveillance .\n","Ground Truth French: en même temps , je tremble à l' idée que nous sommes entourés par un réseau d' informateurs et je me demande si l' objectif de cette clarté n' était pas de nous le rappeler et de nous avertir que nos moindres écarts de conduite sont sous constante surveillance .\n","Predicted Translation: en ce qui concerne la proposition de la commission , je voudrais dire que la commission a été adoptée par le conseil , qui a été dit , je ne pas pas de faire en sorte que les députés européens ont été dit . <end>\n","\n","English: our common aim now is to implement all the steps we have been talking about , to put them into practice and to look for feedback .\n","Ground Truth French: à l' heure actuelle , notre objectif commun est de mettre en œuvre toutes les mesures dont nous avons parlé , de les mettre en pratique et d' analyser leurs effets .\n","Predicted Translation: je voudrais également remercier le rapporteur , je voudrais remercier le rapporteur pour la commission , qui a été dit , je suis très heureux que nous avons besoin de faire . <end>\n","\n","English: a survey revealed that 70 % of consumers had confidence in the health-related claims made by manufacturers , and that is what makes this regulation a key piece of legislation , not only in terms of greater transparency in consumer protection , but also of improved health protection .\n","Ground Truth French: un sondage a révélé que 70 % des consommateurs font confiance aux allégations des fabricants relatives à la santé . c' est ce qui fait de ce règlement une pièce maîtresse de la législation , non seulement pour augmenter la transparence dans le cadre de la protection des consommateurs mais aussi pour améliorer la protection de la santé .\n","Predicted Translation: je voudrais également remercier le rapporteur , je voudrais remercier le rapporteur pour la commission , qui a été dit , je suis très heureux que nous avons besoin de faire en sorte que les états membres soient prises pour les plus grande partie de la commission , qui ne peut pas être en plus . <end>\n","\n","English: more precisely , castro limits cubans .\n","Ground Truth French: plus précisément , castro limite les cubains .\n","Predicted Translation: en outre , la commission a été adoptée . <end>\n","\n","English: the portuguese presidency has highlighted the need for the european union to combine its highly important international role as the main donor with a leading role - and a more active one - in this movement to reform international development policies , and to create greater scope for coordination , in particular with the united nations system and the bretton woods system .\n","Ground Truth French: la présidence portugaise insiste sur la nécessité pour l' union européenne de rendre plus compatible son rôle important à l' échelle internationale , comme principal donateur , avec un rôle directeur et plus actif dans ce mouvement de rénovation des politiques de développement , à l' échelle internationale , en accroissant sa capacité d' articulation et de coordination , notamment avec le système des nations unies et le système de bretton woods .\n","Predicted Translation: je voudrais également dire que la commission a été adoptée par le conseil , qui a été dit , je ne pas pas de faire en sorte que les députés européens , qui ont été dit , je ne pas pas le faire , à la commission , qui a été dit , je suis très heureux que nous avons besoin de faire en sorte que les états membres ne sont pas plus tard . <end>\n","\n","English: the easing of the situation in serbia - if one can call it that - has brought kosovo back towards centre stage , and that is a good thing .\n","Ground Truth French: le retour au calme en serbie - pour autant qu' on puisse qualifier ainsi la situation - a remis le kosovo sous les feux de l' actualité ; tant mieux .\n","Predicted Translation: je voudrais également remercier le rapporteur , je voudrais remercier le rapporteur pour la commission , qui a été dit , je suis très heureux de la commission . <end>\n","\n","English: it is preparing itself to take draconian measures , with a further 1 000 job cuts on top of the 2 500 already announced .\n","Ground Truth French: l' on s' y prépare à une sorte de cure d' austérité qui entraînera 1 000 licenciements en plus des 2 500 déjà annoncé .\n","Predicted Translation: je voudrais également remercier le rapporteur , je voudrais remercier le rapporteur pour la commission , qui a été dit , je suis très heureux de la commission . <end>\n","\n","English: new york - after a hard-fought election campaign , costing well in excess of $ 2 billion , it seems to many observers that not much has changed in american politics : barack obama is still president , the republicans still control the house of representatives , and the democrats still have a majority in the senate .\n","Ground Truth French: new-york - après une campagne électorale féroce qui a coûté plus de 2 milliards de dollars , beaucoup d' observateurs ont l' impression que la vie politique américaine n' a guère changé . obama est toujours président , les républicains contrôlent toujours la chambre des représentants , tandis que les démocrates conservent la majorité au sénat .\n","Predicted Translation: en ce qui concerne la proposition de la commission , je voudrais dire que la commission a été adoptée par le conseil , qui a été dit , je ne pas pas de faire en sorte que les députés européens , qui ont été dit , je ne pas pas le faire , à la commission , qui a été dit , je suis très brièvement que la commission a été adoptée . <end>\n","\n","English: but for the intermediate less-favoured areas , there is an agreement that we need to change the approach in the light of the criticism from the european court of auditors , which is also shared by this parliament .\n","Ground Truth French: cependant , en ce qui concerne les zones défavorisées intermédiaires , il existe un accord prévoyant que nous changions notre approche à la lumière des critiques formulées par la cour des comptes européenne , avis que partage également le parlement .\n","Predicted Translation: monsieur le président , je voudrais remercier le rapporteur , monsieur le commissaire , je voudrais remercier le rapporteur , je voudrais remercier le rapporteur pour la commission , qui a été dit , je suis très heureux que nous avons besoin de faire . <end>\n","\n","English: piracy causes victims and generates huge revenues for the practitioners of this ' profession ' .\n","Ground Truth French: la piraterie fait des victimes et génère des profits considérables pour ceux qui pratiquent ce \" métier \" .\n","Predicted Translation: la commission a été adoptée par le président , je voudrais dire que la commission a été adoptée . <end>\n","\n","English: the same can be said for the people 's car , the tata , that is now being manufactured in india .\n","Ground Truth French: il en va de même de la voiture du peuple , la tata , qui est actuellement fabriquée en inde .\n","Predicted Translation: je voudrais également dire que la commission a été adoptée par le conseil , qui a été dit . <end>\n","\n","English: however , it is , of course , very important to bring about an intensification of the interethnic dialogue in various ways .\n","Ground Truth French: en revanche , il est bien sûr urgent de procéder , de diverses manières , à une intensification du dialogue interethnique .\n","Predicted Translation: en outre , je voudrais dire que la commission a été adoptée par le conseil , qui a été dit . <end>\n","\n","English: the rolling jubilee is a timely reminder of the continuing relevance of one of the oldest laws of social life .\n","Ground Truth French: the rolling jubilee est un rappel opportun de la pertinence de l' une des plus anciennes lois de la vie sociale .\n","Predicted Translation: je voudrais également dire que la commission a été adoptée par le conseil , qui a été dit . <end>\n","\n","English: with a 37 % reduction under the heading of growth and competitiveness , and a 10 % reduction in the cohesion fund , the financial perspective destroys any notion of a revival of europe and precludes any new policy for seven years .\n","Ground Truth French: avec une diminution de 37 % au titre de la croissance et de la compétitivité , de 10 % sur les fonds de cohésion , elles annihilent toute idée de relance européenne et interdisent toute politique nouvelle pendant sept ans .\n","Predicted Translation: en ce qui concerne la proposition de la commission , je voudrais dire que la commission a été adoptée par le conseil , qui a été dit , je ne pas pas de faire en sorte que les députés européens , qui ont été dit . <end>\n","\n","English: the copenhagen criteria have been the yardstick for measuring the countries ' political and economic reforms .\n","Ground Truth French: les critères de copenhague ont constitué la base d' évaluation des réformes politiques et économiques de ces pays .\n","Predicted Translation: la commission a été dit , je suis très heureux que nous avons besoin de faire en sorte que les états membres . <end>\n","\n","English: and what has happened ?\n","Ground Truth French: que s' est-il passé ?\n","Predicted Translation: en ce qui concerne la proposition de la commission . <end>\n","\n"]}]},{"cell_type":"markdown","source":["# Conclusion"],"metadata":{"id":"rgi-YRQTFDlj"}},{"cell_type":"markdown","source":["The result of my models are ok. My dataset translates English to French and is from https://www.statmt.org/europarl/ .My code was done in Google Colab, so the cells at the beginning of the notebook are so that everything runs correctly. Overall, I that the LSTM performed the best, follwowed by the GRU model and then the simpleRNN. I did not use an attention layer in my models so they suffered from the data bottleneck problem and I used greedy decoding. Both of these decisions definitely contributed to the ok performance. Furthermore, it seemed that the GRU model is overfitting, however I am not totally sure why as I include dropout and the other models don't overfit. Maybe with a larger dropout this could be avoided. For calculating the BLEU score, I did not use the entire validation or training set, but instead I used a subset to save time. This still provides an indication of how the models performed, but it reduces runtime for each calculation from 40 minutes plus to 10 minutes. On the validation set, LSTM performed the best with .04 on average, followed by simpleRNN with 0.0389 and the GRU with 0.033. The poor performance in GRU is likely due to overfitting. The bleu score was much lower however on the test set at only .01. The translations could definetly be better, as there is a lot of repetition and many things that don't need to be there. However, ther are also things that look promising. For example The sentence \"mr president , ladies and gentlemen , i would like to thank mrs lynne for her work .\" should be translated to \"monsieur le président , mesdames et messieurs , j' aimerais remercier mme lynne pour son travail .\" and it was predicted as \"monsieur le président , je voudrais remercier le rapporteur , monsieur le commissaire , je voudrais remercier le rapporteur . end\" It translates the beginning correctly, but then seems to trail off. The tranlations also seem to be around the same length as the actual translations which is promising. "],"metadata":{"id":"zLu68BUwH7PP"}},{"cell_type":"code","source":[""],"metadata":{"id":"IJPG-XJ2MerW"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"CS584-Assignment4-s22.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"widgets":{"application/vnd.jupyter.widget-state+json":{"ebe0f045034148429e0f0f2872a3fac4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_14043a5696af4a38a93b53380ca2f8ea","IPY_MODEL_3be6153bd8bd417cb1bdd0988680f0dd","IPY_MODEL_fb58e118cf5e441e9af46318fd6732de"],"layout":"IPY_MODEL_f9f2630ef4454612b015dc275b4065ed"}},"14043a5696af4a38a93b53380ca2f8ea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_86d9e4c2b4224853904cac808a23a083","placeholder":"​","style":"IPY_MODEL_ad5f23544dab4cf9b63ebc195802154c","value":"100%"}},"3be6153bd8bd417cb1bdd0988680f0dd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f7c016c8bb5d488abadaf8b705c1e2ef","max":300,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7c1952e067774268b7161e6a3e65b99c","value":300}},"fb58e118cf5e441e9af46318fd6732de":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2aeae9cd4d624a85b165b14d61e35311","placeholder":"​","style":"IPY_MODEL_fd82f923d7de4a68b6f0603d5d1809fc","value":" 300/300 [07:55&lt;00:00,  2.41s/it]"}},"f9f2630ef4454612b015dc275b4065ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"86d9e4c2b4224853904cac808a23a083":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad5f23544dab4cf9b63ebc195802154c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f7c016c8bb5d488abadaf8b705c1e2ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c1952e067774268b7161e6a3e65b99c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2aeae9cd4d624a85b165b14d61e35311":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd82f923d7de4a68b6f0603d5d1809fc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dcca7800c9bb448d84c13e8bbab4e70e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_08274abe4caa4614bcba0ebd1726c550","IPY_MODEL_e645281fd7d54ea692859012ae10f347","IPY_MODEL_ff424a8910b1480590d67234a19fa932"],"layout":"IPY_MODEL_4eb503b560134436a5fe21a833a05ed4"}},"08274abe4caa4614bcba0ebd1726c550":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ba11e18a14364f71b5a9cb74475724dd","placeholder":"​","style":"IPY_MODEL_1d0bdcf5c13b4015a621e3e62791cc2d","value":"100%"}},"e645281fd7d54ea692859012ae10f347":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fa373e69f48c46ea8f1e93766753fb1e","max":300,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5d6aa76eeeda465c82b08f3113e7b844","value":300}},"ff424a8910b1480590d67234a19fa932":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a2e3411a2d44c438dd5227fb1a83f53","placeholder":"​","style":"IPY_MODEL_85eca978857544009e2449190ccadc67","value":" 300/300 [08:18&lt;00:00,  2.23s/it]"}},"4eb503b560134436a5fe21a833a05ed4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba11e18a14364f71b5a9cb74475724dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d0bdcf5c13b4015a621e3e62791cc2d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fa373e69f48c46ea8f1e93766753fb1e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d6aa76eeeda465c82b08f3113e7b844":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2a2e3411a2d44c438dd5227fb1a83f53":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"85eca978857544009e2449190ccadc67":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"389e115f13d846549d06d5c20ae4c272":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_729d92711825439098a2e3cb4259c5cf","IPY_MODEL_bfe8117fe9d44ac7b01c38eb18e100f0","IPY_MODEL_f765c36d8d554577b352d532ded1a471"],"layout":"IPY_MODEL_fcb32ecccb414cdab62422484f52c336"}},"729d92711825439098a2e3cb4259c5cf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_240795d0a32b4cc8abec4c7b9af1ab7f","placeholder":"​","style":"IPY_MODEL_9b2c7456f0e74dc4a104a38604ada858","value":"100%"}},"bfe8117fe9d44ac7b01c38eb18e100f0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_38045702e5f04369b7c3df80fd148755","max":300,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5ec9656f13c04d8581179ebfc50ac5ad","value":300}},"f765c36d8d554577b352d532ded1a471":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_139d10a8df0c45678bdcff533c0d2a4d","placeholder":"​","style":"IPY_MODEL_314b9e716c964cb2a879688c56a0c09f","value":" 300/300 [07:51&lt;00:00,  1.74s/it]"}},"fcb32ecccb414cdab62422484f52c336":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"240795d0a32b4cc8abec4c7b9af1ab7f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b2c7456f0e74dc4a104a38604ada858":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"38045702e5f04369b7c3df80fd148755":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ec9656f13c04d8581179ebfc50ac5ad":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"139d10a8df0c45678bdcff533c0d2a4d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"314b9e716c964cb2a879688c56a0c09f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"24b198502bd849b5b63b3e5a38b1ec3b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7b3d59daf35f4c2487d5ed7911ae33ca","IPY_MODEL_e9963d4b55a0463eb466947135347b9b","IPY_MODEL_2a33f1aee00943c0ab65cc2c541c977a"],"layout":"IPY_MODEL_13319d1d0b224c6a834cdb0f9cf4e8fa"}},"7b3d59daf35f4c2487d5ed7911ae33ca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_35b181d5d9d349debd06272f858bb9e3","placeholder":"​","style":"IPY_MODEL_a9ff4a4a2fc84e3fac875ca11f445e2f","value":"100%"}},"e9963d4b55a0463eb466947135347b9b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e9ae467506c9412c8c82def6e27bbcc2","max":100,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d6bea26ab15844dcac0d7e0c822b1d4c","value":100}},"2a33f1aee00943c0ab65cc2c541c977a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7073b426fabf486cb5809f9a486617a9","placeholder":"​","style":"IPY_MODEL_dcc0ac0dd31846ea88bcab2464ab5279","value":" 100/100 [02:23&lt;00:00,  1.46s/it]"}},"13319d1d0b224c6a834cdb0f9cf4e8fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"35b181d5d9d349debd06272f858bb9e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9ff4a4a2fc84e3fac875ca11f445e2f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e9ae467506c9412c8c82def6e27bbcc2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6bea26ab15844dcac0d7e0c822b1d4c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7073b426fabf486cb5809f9a486617a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dcc0ac0dd31846ea88bcab2464ab5279":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"172eff5d21204ae68115f5401e064b2b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4f54c2fd1d174b108e55cec207634ceb","IPY_MODEL_a37daf1d9dba457c891016d3db4a1210","IPY_MODEL_7ff836633b6348199a339053cab2ae45"],"layout":"IPY_MODEL_eaaed0ca7b794ed7817bc12e7e1d87fb"}},"4f54c2fd1d174b108e55cec207634ceb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5e48c23a90e24298afd9468b8458aecd","placeholder":"​","style":"IPY_MODEL_69b77f74cd364aaa9e9accfd583c404c","value":"100%"}},"a37daf1d9dba457c891016d3db4a1210":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_62baa95a4c3e4a8bbe9534ccd4d22bc4","max":2249121,"min":0,"orientation":"horizontal","style":"IPY_MODEL_58a8c8dd878f4af5a29ef4f601223f4d","value":2249121}},"7ff836633b6348199a339053cab2ae45":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_23c83ab6a7c44add90b235c28ca98817","placeholder":"​","style":"IPY_MODEL_dca1817cbc4c450dac2b2fffb107a574","value":" 2249121/2249121 [00:03&lt;00:00, 799040.05it/s]"}},"eaaed0ca7b794ed7817bc12e7e1d87fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e48c23a90e24298afd9468b8458aecd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69b77f74cd364aaa9e9accfd583c404c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"62baa95a4c3e4a8bbe9534ccd4d22bc4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"58a8c8dd878f4af5a29ef4f601223f4d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"23c83ab6a7c44add90b235c28ca98817":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dca1817cbc4c450dac2b2fffb107a574":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d4d12332c04c415ab7c5eb159a95344b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_55e9b0cca5164ef5b6ca9d63c7078c44","IPY_MODEL_3466945006b3461992b88aca898ed29a","IPY_MODEL_bbf7c76eeda240a3a0aaee74aed7fd5e"],"layout":"IPY_MODEL_ba8f6a746a7a4d328c64b8f7a2f7f4f3"}},"55e9b0cca5164ef5b6ca9d63c7078c44":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b00429aed6bc43d79dcb029cf19bd4e0","placeholder":"​","style":"IPY_MODEL_3c62aaeb3d17419686d361746ad60288","value":"100%"}},"3466945006b3461992b88aca898ed29a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d72f7e185e942728799ed9a92320116","max":2249121,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e3dd2e64e301461dae801fd32480b98d","value":2249121}},"bbf7c76eeda240a3a0aaee74aed7fd5e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5305b71cbef5486cb26ab296aabd9939","placeholder":"​","style":"IPY_MODEL_f212df33859a45f0ad5c2c79cf688d9d","value":" 2249121/2249121 [00:04&lt;00:00, 561268.53it/s]"}},"ba8f6a746a7a4d328c64b8f7a2f7f4f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b00429aed6bc43d79dcb029cf19bd4e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c62aaeb3d17419686d361746ad60288":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7d72f7e185e942728799ed9a92320116":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e3dd2e64e301461dae801fd32480b98d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5305b71cbef5486cb26ab296aabd9939":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f212df33859a45f0ad5c2c79cf688d9d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c844be712c194aa29028e1d763789c78":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d477aa8d619e4b7bb037306623bd19a3","IPY_MODEL_5e865093350c419886aa43863204df14","IPY_MODEL_b1bcfd5ce0514247b94e61f6581c2141"],"layout":"IPY_MODEL_2b7e0bd0c45e4c8fad601c2a3bc0e42c"}},"d477aa8d619e4b7bb037306623bd19a3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_efc9c6fc771b4fc4bc3e94271f8d4fe8","placeholder":"​","style":"IPY_MODEL_7c67a1bef5b44e378afe9d826101dc71","value":"en: 100%"}},"5e865093350c419886aa43863204df14":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a9ef160c5c84156a1f46fae7e994b51","max":12800,"min":0,"orientation":"horizontal","style":"IPY_MODEL_adfa4e45e2be408194a8e44475692604","value":12800}},"b1bcfd5ce0514247b94e61f6581c2141":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_da56f0a489ce4e94b9d0888c5fd00ed7","placeholder":"​","style":"IPY_MODEL_a0caa12f86fa409b9e2c52dda8df05e2","value":" 12800/12800 [02:35&lt;00:00, 90.92it/s]"}},"2b7e0bd0c45e4c8fad601c2a3bc0e42c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"efc9c6fc771b4fc4bc3e94271f8d4fe8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c67a1bef5b44e378afe9d826101dc71":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2a9ef160c5c84156a1f46fae7e994b51":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"adfa4e45e2be408194a8e44475692604":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"da56f0a489ce4e94b9d0888c5fd00ed7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0caa12f86fa409b9e2c52dda8df05e2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"11b101e25cd04e9f9cc3d39defab8dff":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_79b9af8359ba4c9bb2030d19a636320d","IPY_MODEL_62569de5a23c43f9baa3f5650caba26c","IPY_MODEL_b292e07034454c859c129ca07b4bc0fe"],"layout":"IPY_MODEL_3bf82d5c762648e3b2523a7ac5e280a9"}},"79b9af8359ba4c9bb2030d19a636320d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_88b05119cfd94151913df6cca1c00f0f","placeholder":"​","style":"IPY_MODEL_2cc8740da09f40c68da52c1c832c2b97","value":"es: 100%"}},"62569de5a23c43f9baa3f5650caba26c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c30c4bf4de5a47e6973fc563346871f2","max":12800,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9f9b383f451045e383035cf6eb5e5753","value":12800}},"b292e07034454c859c129ca07b4bc0fe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b6f0941727ee4833822ced7391b30a8d","placeholder":"​","style":"IPY_MODEL_02007b5dc3fd4399bf189e996caa65e9","value":" 12800/12800 [02:25&lt;00:00, 84.31it/s]"}},"3bf82d5c762648e3b2523a7ac5e280a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"88b05119cfd94151913df6cca1c00f0f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2cc8740da09f40c68da52c1c832c2b97":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c30c4bf4de5a47e6973fc563346871f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f9b383f451045e383035cf6eb5e5753":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b6f0941727ee4833822ced7391b30a8d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"02007b5dc3fd4399bf189e996caa65e9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}